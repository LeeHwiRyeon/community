/**
 * ğŸ¤ ìŒì„± AI ì‹œìŠ¤í…œ
 * 
 * ìŒì„± ì¸ì‹, ìŒì„± ëª…ë ¹, ìŒì„± í•©ì„±ì„ ì§€ì›í•˜ëŠ”
 * í•¸ì¦ˆí”„ë¦¬ ì»¨í…ì¸  ì œì‘ ë° ì œì–´ ì‹œìŠ¤í…œ
 * 
 * @author AUTOAGENTS Manager
 * @version 3.0.0
 * @created 2025-10-02
 */

import React, {
    useState,
    useEffect,
    useCallback,
    useRef,
    createContext,
    useContext,
    ReactNode
} from 'react';
import {
    Box,
    Paper,
    Typography,
    Button,
    IconButton,
    Card,
    CardContent,
    Dialog,
    DialogTitle,
    DialogContent,
    DialogActions,
    TextField,
    Slider,
    FormControl,
    InputLabel,
    Select,
    MenuItem,
    Chip,
    List,
    ListItem,
    ListItemText,
    ListItemIcon,
    ListItemSecondaryAction,
    Avatar,
    LinearProgress,
    Alert,
    Tooltip,
    Switch,
    FormControlLabel,
    useTheme
} from '@mui/material';
import {
    Mic as MicIcon,
    MicOff as MicOffIcon,
    VolumeUp as VolumeUpIcon,
    VolumeOff as VolumeOffIcon,
    RecordVoiceOver as VoiceIcon,
    Hearing as HearingIcon,
    Translate as TranslateIcon,
    Settings as SettingsIcon,
    PlayArrow as PlayIcon,
    Pause as PauseIcon,
    Stop as StopIcon,
    Save as SaveIcon,
    Delete as DeleteIcon,
    Edit as EditIcon,
    Add as AddIcon,
    Psychology as AIIcon,
    GraphicEq as WaveformIcon,
    GraphicEq as EqualizerIcon,
    Speed as SpeedIcon,
    Tune as TuneIcon
} from '@mui/icons-material';
import { styled, keyframes } from '@mui/system';

// Web Speech API íƒ€ì… ì •ì˜
declare global {
    interface Window {
        SpeechRecognition: any;
        webkitSpeechRecognition: any;
    }
}

interface SpeechRecognition {
    continuous: boolean;
    interimResults: boolean;
    lang: string;
    onresult: (event: any) => void;
    onerror: (event: any) => void;
    onstart: () => void;
    onend: () => void;
    start: () => void;
    stop: () => void;
}

// ìŒì„± AI íƒ€ì… ì •ì˜
export type VoiceCommand = {
    id: string;
    trigger: string[];
    action: string;
    description: string;
    category: 'navigation' | 'editing' | 'creation' | 'system' | 'custom';
    parameters?: Record<string, any>;
    enabled: boolean;
};

export type VoiceRecognitionLanguage = 'ko-KR' | 'en-US' | 'ja-JP' | 'zh-CN' | 'es-ES' | 'fr-FR';

export interface VoiceSettings {
    recognition: {
        language: VoiceRecognitionLanguage;
        continuous: boolean;
        interimResults: boolean;
        maxAlternatives: number;
        sensitivity: number;
        noiseReduction: boolean;
    };
    synthesis: {
        voice: string;
        rate: number;
        pitch: number;
        volume: number;
        language: string;
    };
    commands: {
        wakeWord: string;
        confirmationRequired: boolean;
        timeout: number;
        customCommands: VoiceCommand[];
    };
    ai: {
        enableNLP: boolean;
        contextAware: boolean;
        learningMode: boolean;
        personalizedResponses: boolean;
    };
}

export interface VoiceSession {
    id: string;
    startTime: Date;
    endTime?: Date;
    transcript: string;
    confidence: number;
    commands: string[];
    language: VoiceRecognitionLanguage;
    duration: number;
}

interface VoiceAIContextValue {
    isListening: boolean;
    isSpeaking: boolean;
    currentTranscript: string;
    confidence: number;
    sessions: VoiceSession[];
    settings: VoiceSettings;
    availableVoices: SpeechSynthesisVoice[];

    // ìŒì„± ì¸ì‹
    startListening: () => void;
    stopListening: () => void;

    // ìŒì„± í•©ì„±
    speak: (text: string, options?: Partial<VoiceSettings['synthesis']>) => void;
    stopSpeaking: () => void;

    // ëª…ë ¹ ì²˜ë¦¬
    executeCommand: (command: string) => void;
    addCustomCommand: (command: VoiceCommand) => void;
    removeCustomCommand: (commandId: string) => void;

    // ì„¤ì •
    updateSettings: (newSettings: Partial<VoiceSettings>) => void;

    // AI ê¸°ëŠ¥
    processNaturalLanguage: (text: string) => Promise<string>;
    getContextualSuggestions: () => string[];
}

// ê¸°ë³¸ ì„¤ì •
const DEFAULT_VOICE_SETTINGS: VoiceSettings = {
    recognition: {
        language: 'ko-KR',
        continuous: true,
        interimResults: true,
        maxAlternatives: 3,
        sensitivity: 0.7,
        noiseReduction: true
    },
    synthesis: {
        voice: '',
        rate: 1.0,
        pitch: 1.0,
        volume: 0.8,
        language: 'ko-KR'
    },
    commands: {
        wakeWord: 'ì•ˆë…• ì—ì´ì „íŠ¸',
        confirmationRequired: false,
        timeout: 5000,
        customCommands: []
    },
    ai: {
        enableNLP: true,
        contextAware: true,
        learningMode: true,
        personalizedResponses: true
    }
};

// ê¸°ë³¸ ìŒì„± ëª…ë ¹ë“¤
const DEFAULT_COMMANDS: VoiceCommand[] = [
    {
        id: 'create-post',
        trigger: ['ìƒˆ ê¸€ ì‘ì„±', 'í¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°', 'ê¸€ì“°ê¸° ì‹œì‘'],
        action: 'CREATE_POST',
        description: 'ìƒˆë¡œìš´ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤',
        category: 'creation',
        enabled: true
    },
    {
        id: 'save-content',
        trigger: ['ì €ì¥', 'ì €ì¥í•´ì¤˜', 'ì„¸ì´ë¸Œ'],
        action: 'SAVE_CONTENT',
        description: 'í˜„ì¬ ë‚´ìš©ì„ ì €ì¥í•©ë‹ˆë‹¤',
        category: 'editing',
        enabled: true
    },
    {
        id: 'navigate-home',
        trigger: ['í™ˆìœ¼ë¡œ', 'ë©”ì¸ìœ¼ë¡œ', 'ì²˜ìŒìœ¼ë¡œ'],
        action: 'NAVIGATE_HOME',
        description: 'í™ˆ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤',
        category: 'navigation',
        enabled: true
    },
    {
        id: 'toggle-dark-mode',
        trigger: ['ë‹¤í¬ëª¨ë“œ', 'ì–´ë‘ìš´ í…Œë§ˆ', 'ë°ì€ í…Œë§ˆ'],
        action: 'TOGGLE_THEME',
        description: 'í…Œë§ˆë¥¼ ë³€ê²½í•©ë‹ˆë‹¤',
        category: 'system',
        enabled: true
    },
    {
        id: 'read-content',
        trigger: ['ì½ì–´ì¤˜', 'ì½ê¸°', 'ìŒì„±ìœ¼ë¡œ ì½ê¸°'],
        action: 'READ_CONTENT',
        description: 'í˜„ì¬ ë‚´ìš©ì„ ìŒì„±ìœ¼ë¡œ ì½ì–´ì¤ë‹ˆë‹¤',
        category: 'system',
        enabled: true
    }
];

// ì• ë‹ˆë©”ì´ì…˜
const pulseAnimation = keyframes`
    0% { transform: scale(1); opacity: 1; }
    50% { transform: scale(1.1); opacity: 0.7; }
    100% { transform: scale(1); opacity: 1; }
`;

const waveAnimation = keyframes`
    0%, 100% { height: 20px; }
    25% { height: 40px; }
    50% { height: 60px; }
    75% { height: 30px; }
`;

// ìŠ¤íƒ€ì¼ë“œ ì»´í¬ë„ŒíŠ¸
const VoiceContainer = styled(Paper)(({ theme }) => ({
    height: '100%',
    display: 'flex',
    flexDirection: 'column',
    overflow: 'hidden'
}));

const VoiceVisualizer = styled(Box)<{ isActive: boolean }>(({ theme, isActive }) => ({
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    height: 100,
    backgroundColor: theme.palette.background.default,
    borderRadius: theme.shape.borderRadius,
    margin: theme.spacing(2),
    position: 'relative',

    '&::before': {
        content: '""',
        position: 'absolute',
        width: '100%',
        height: '100%',
        borderRadius: theme.shape.borderRadius,
        background: isActive ?
            `radial-gradient(circle, ${theme.palette.primary.light}20 0%, transparent 70%)` :
            'transparent',
        animation: isActive ? `${pulseAnimation} 2s infinite` : 'none'
    }
}));

const WaveBar = styled(Box)<{ isActive: boolean; delay: number }>(({ theme, isActive, delay }) => ({
    width: 4,
    backgroundColor: theme.palette.primary.main,
    margin: '0 2px',
    borderRadius: 2,
    animation: isActive ? `${waveAnimation} 1s infinite ${delay}s` : 'none',
    height: isActive ? 20 : 10,
    transition: 'height 0.3s ease'
}));

const CommandChip = styled(Chip)<{ category: VoiceCommand['category'] }>(({ theme, category }) => ({
    backgroundColor:
        category === 'navigation' ? theme.palette.info.light :
            category === 'editing' ? theme.palette.success.light :
                category === 'creation' ? theme.palette.primary.light :
                    category === 'system' ? theme.palette.warning.light :
                        theme.palette.grey[300],
    margin: theme.spacing(0.5)
}));

// ìŒì„± AI ì»¨í…ìŠ¤íŠ¸
const VoiceAIContext = createContext<VoiceAIContextValue | undefined>(undefined);

// ì»¤ìŠ¤í…€ í›…
export const useVoiceAI = (): VoiceAIContextValue => {
    const context = useContext(VoiceAIContext);
    if (!context) {
        throw new Error('useVoiceAI must be used within VoiceAIProvider');
    }
    return context;
};

// ìŒì„± ì¸ì‹ í›…
const useSpeechRecognition = () => {
    const [isListening, setIsListening] = useState(false);
    const [transcript, setTranscript] = useState('');
    const [confidence, setConfidence] = useState(0);
    const recognitionRef = useRef<SpeechRecognition | null>(null);

    useEffect(() => {
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
            recognitionRef.current = new SpeechRecognition();
        }
    }, []);

    const startListening = useCallback((settings: VoiceSettings['recognition']) => {
        if (!recognitionRef.current) return;

        const recognition = recognitionRef.current;
        recognition.continuous = settings.continuous;
        recognition.interimResults = settings.interimResults;
        recognition.lang = settings.language;
        // recognition.maxAlternatives = settings.maxAlternatives; // Property not available in all browsers

        recognition.onstart = () => setIsListening(true);
        recognition.onend = () => setIsListening(false);

        recognition.onresult = (event) => {
            let finalTranscript = '';
            let interimTranscript = '';

            for (let i = event.resultIndex; i < event.results.length; i++) {
                const result = event.results[i];
                if (result.isFinal) {
                    finalTranscript += result[0].transcript;
                    setConfidence(result[0].confidence);
                } else {
                    interimTranscript += result[0].transcript;
                }
            }

            setTranscript(finalTranscript || interimTranscript);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            setIsListening(false);
        };

        recognition.start();
    }, []);

    const stopListening = useCallback(() => {
        if (recognitionRef.current) {
            recognitionRef.current.stop();
        }
    }, []);

    return { isListening, transcript, confidence, startListening, stopListening };
};

// ìŒì„± í•©ì„± í›…
const useSpeechSynthesis = () => {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [availableVoices, setAvailableVoices] = useState<SpeechSynthesisVoice[]>([]);

    useEffect(() => {
        const updateVoices = () => {
            setAvailableVoices(speechSynthesis.getVoices());
        };

        updateVoices();
        speechSynthesis.addEventListener('voiceschanged', updateVoices);

        return () => {
            speechSynthesis.removeEventListener('voiceschanged', updateVoices);
        };
    }, []);

    const speak = useCallback((text: string, options: Partial<VoiceSettings['synthesis']> = {}) => {
        if (!text) return;

        const utterance = new SpeechSynthesisUtterance(text);

        if (options.voice) {
            const voice = availableVoices.find(v => v.name === options.voice);
            if (voice) utterance.voice = voice;
        }

        utterance.rate = options.rate || 1.0;
        utterance.pitch = options.pitch || 1.0;
        utterance.volume = options.volume || 0.8;
        utterance.lang = options.language || 'ko-KR';

        utterance.onstart = () => setIsSpeaking(true);
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = () => setIsSpeaking(false);

        speechSynthesis.speak(utterance);
    }, [availableVoices]);

    const stopSpeaking = useCallback(() => {
        speechSynthesis.cancel();
        setIsSpeaking(false);
    }, []);

    return { isSpeaking, availableVoices, speak, stopSpeaking };
};

// ìŒì„± AI í”„ë¡œë°”ì´ë”
interface VoiceAIProviderProps {
    children: ReactNode;
}

export const VoiceAIProvider: React.FC<VoiceAIProviderProps> = ({ children }) => {
    const [settings, setSettings] = useState<VoiceSettings>(() => {
        try {
            const saved = localStorage.getItem('voice-ai-settings');
            return saved ? { ...DEFAULT_VOICE_SETTINGS, ...JSON.parse(saved) } : DEFAULT_VOICE_SETTINGS;
        } catch {
            return DEFAULT_VOICE_SETTINGS;
        }
    });

    const [sessions, setSessions] = useState<VoiceSession[]>([]);
    const [commands, setCommands] = useState<VoiceCommand[]>(DEFAULT_COMMANDS);

    const speechRecognition = useSpeechRecognition();
    const speechSynthesis = useSpeechSynthesis();

    // ëª…ë ¹ ì‹¤í–‰
    const executeCommand = useCallback((commandText: string) => {
        const matchedCommand = commands.find(cmd =>
            cmd.enabled && cmd.trigger.some(trigger =>
                commandText.toLowerCase().includes(trigger.toLowerCase())
            )
        );

        if (matchedCommand) {
            console.log('Executing command:', matchedCommand.action);

            switch (matchedCommand.action) {
                case 'CREATE_POST':
                    // ìƒˆ ê¸€ ì‘ì„± ë¡œì§
                    speechSynthesis.speak('ìƒˆë¡œìš´ ê¸€ ì‘ì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.');
                    break;

                case 'SAVE_CONTENT':
                    // ì €ì¥ ë¡œì§
                    speechSynthesis.speak('ë‚´ìš©ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.');
                    break;

                case 'NAVIGATE_HOME':
                    // í™ˆ ì´ë™ ë¡œì§
                    speechSynthesis.speak('í™ˆ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.');
                    break;

                case 'TOGGLE_THEME':
                    // í…Œë§ˆ ë³€ê²½ ë¡œì§
                    speechSynthesis.speak('í…Œë§ˆë¥¼ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.');
                    break;

                case 'READ_CONTENT':
                    // ì»¨í…ì¸  ì½ê¸° ë¡œì§
                    const content = document.querySelector('main')?.textContent || 'ì½ì„ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.';
                    speechSynthesis.speak(content.substring(0, 500));
                    break;

                default:
                    speechSynthesis.speak('ëª…ë ¹ì„ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤.');
            }
        } else {
            speechSynthesis.speak('ì¸ì‹ëœ ëª…ë ¹ì´ ì—†ìŠµë‹ˆë‹¤.');
        }
    }, [commands, speechSynthesis]);

    // ìì—°ì–´ ì²˜ë¦¬ (ëª¨ì˜ AI)
    const processNaturalLanguage = useCallback(async (text: string): Promise<string> => {
        // ì‹¤ì œë¡œëŠ” AI API í˜¸ì¶œ
        await new Promise(resolve => setTimeout(resolve, 1000));

        if (text.includes('ì•ˆë…•') || text.includes('hello')) {
            return 'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?';
        } else if (text.includes('ë„ì›€') || text.includes('help')) {
            return 'ìŒì„± ëª…ë ¹ìœ¼ë¡œ ê¸€ ì‘ì„±, ì €ì¥, ë„¤ë¹„ê²Œì´ì…˜ ë“±ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
        } else if (text.includes('ëª…ë ¹') || text.includes('command')) {
            return `ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹: ${commands.map(c => c.trigger[0]).join(', ')}`;
        } else {
            return 'ì£„ì†¡í•©ë‹ˆë‹¤. ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.';
        }
    }, [commands]);

    // ìƒí™©ë³„ ì œì•ˆ
    const getContextualSuggestions = useCallback((): string[] => {
        const currentPath = window.location.pathname;

        if (currentPath.includes('write') || currentPath.includes('edit')) {
            return ['ì €ì¥í•´ì¤˜', 'ì½ì–´ì¤˜', 'ë§ì¶¤ë²• ê²€ì‚¬'];
        } else if (currentPath.includes('home')) {
            return ['ìƒˆ ê¸€ ì‘ì„±', 'ìµœê·¼ ê¸€ ë³´ê¸°', 'ì„¤ì • ì—´ê¸°'];
        } else {
            return ['í™ˆìœ¼ë¡œ', 'ë’¤ë¡œê°€ê¸°', 'ë„ì›€ë§'];
        }
    }, []);

    // ìŒì„± ì¸ì‹ ì‹œì‘
    const startListening = useCallback(() => {
        speechRecognition.startListening(settings.recognition);
    }, [speechRecognition, settings.recognition]);

    // ìŒì„± ì¸ì‹ ì¤‘ì§€
    const stopListening = useCallback(() => {
        speechRecognition.stopListening();
    }, [speechRecognition]);

    // ìŒì„± í•©ì„±
    const speak = useCallback((text: string, options?: Partial<VoiceSettings['synthesis']>) => {
        speechSynthesis.speak(text, { ...settings.synthesis, ...options });
    }, [speechSynthesis, settings.synthesis]);

    // ìŒì„± í•©ì„± ì¤‘ì§€
    const stopSpeaking = useCallback(() => {
        speechSynthesis.stopSpeaking();
    }, [speechSynthesis]);

    // ì»¤ìŠ¤í…€ ëª…ë ¹ ì¶”ê°€
    const addCustomCommand = useCallback((command: VoiceCommand) => {
        setCommands(prev => [...prev, command]);
    }, []);

    // ì»¤ìŠ¤í…€ ëª…ë ¹ ì œê±°
    const removeCustomCommand = useCallback((commandId: string) => {
        setCommands(prev => prev.filter(cmd => cmd.id !== commandId));
    }, []);

    // ì„¤ì • ì—…ë°ì´íŠ¸
    const updateSettings = useCallback((newSettings: Partial<VoiceSettings>) => {
        setSettings(prev => {
            const updated = { ...prev, ...newSettings };
            localStorage.setItem('voice-ai-settings', JSON.stringify(updated));
            return updated;
        });
    }, []);

    // ìŒì„± ì¸ì‹ ê²°ê³¼ ì²˜ë¦¬
    useEffect(() => {
        if (speechRecognition.transcript && speechRecognition.confidence > 0.5) {
            const transcript = speechRecognition.transcript.trim();

            // ì›¨ì´í¬ ì›Œë“œ ì²´í¬
            if (transcript.toLowerCase().includes(settings.commands.wakeWord.toLowerCase())) {
                executeCommand(transcript);
            }

            // ì„¸ì…˜ ê¸°ë¡
            const session: VoiceSession = {
                id: `session-${Date.now()}`,
                startTime: new Date(),
                transcript,
                confidence: speechRecognition.confidence,
                commands: [transcript],
                language: settings.recognition.language,
                duration: 0
            };

            setSessions(prev => [session, ...prev.slice(0, 49)]);
        }
    }, [speechRecognition.transcript, speechRecognition.confidence, settings.commands.wakeWord, executeCommand]);

    const contextValue: VoiceAIContextValue = {
        isListening: speechRecognition.isListening,
        isSpeaking: speechSynthesis.isSpeaking,
        currentTranscript: speechRecognition.transcript,
        confidence: speechRecognition.confidence,
        sessions,
        settings,
        availableVoices: speechSynthesis.availableVoices,
        startListening,
        stopListening,
        speak,
        stopSpeaking,
        executeCommand,
        addCustomCommand,
        removeCustomCommand,
        updateSettings,
        processNaturalLanguage,
        getContextualSuggestions
    };

    return (
        <VoiceAIContext.Provider value={contextValue}>
            {children}
        </VoiceAIContext.Provider>
    );
};

// ìŒì„± ì»¨íŠ¸ë¡¤ íŒ¨ë„
export const VoiceControlPanel: React.FC = () => {
    const {
        isListening,
        isSpeaking,
        currentTranscript,
        confidence,
        sessions,
        settings,
        availableVoices,
        startListening,
        stopListening,
        speak,
        stopSpeaking,
        updateSettings,
        getContextualSuggestions
    } = useVoiceAI();

    const [showSettings, setShowSettings] = useState(false);
    const [testText, setTestText] = useState('ì•ˆë…•í•˜ì„¸ìš”! ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.');

    const theme = useTheme();
    const suggestions = getContextualSuggestions();

    return (
        <VoiceContainer>
            {/* í—¤ë” */}
            <Box p={2} borderBottom={1} borderColor="divider">
                <Box display="flex" justifyContent="space-between" alignItems="center">
                    <Typography variant="h6">ìŒì„± AI ì‹œìŠ¤í…œ</Typography>
                    <Box display="flex" gap={1}>
                        <Chip
                            icon={<MicIcon />}
                            label={isListening ? 'ë“£ëŠ” ì¤‘' : 'ëŒ€ê¸° ì¤‘'}
                            color={isListening ? 'success' : 'default'}
                        />
                        <Chip
                            icon={<VolumeUpIcon />}
                            label={isSpeaking ? 'ë§í•˜ëŠ” ì¤‘' : 'ì¡°ìš©í•¨'}
                            color={isSpeaking ? 'primary' : 'default'}
                        />
                    </Box>
                </Box>
            </Box>

            {/* ìŒì„± ì‹œê°í™” */}
            <VoiceVisualizer isActive={isListening || isSpeaking}>
                <Box display="flex" alignItems="center" gap={0.5}>
                    {Array.from({ length: 20 }, (_, i) => (
                        <WaveBar
                            key={i}
                            isActive={isListening || isSpeaking}
                            delay={i * 0.1}
                        />
                    ))}
                </Box>

                <IconButton
                    sx={{
                        position: 'absolute',
                        width: 60,
                        height: 60,
                        backgroundColor: isListening ? 'error.main' : 'primary.main',
                        color: 'white',
                        '&:hover': {
                            backgroundColor: isListening ? 'error.dark' : 'primary.dark'
                        }
                    }}
                    onClick={isListening ? stopListening : startListening}
                >
                    {isListening ? <MicOffIcon /> : <MicIcon />}
                </IconButton>
            </VoiceVisualizer>

            {/* í˜„ì¬ ì¸ì‹ ê²°ê³¼ */}
            {currentTranscript && (
                <Card sx={{ m: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ì¸ì‹ëœ ìŒì„± (ì‹ ë¢°ë„: {Math.round(confidence * 100)}%)
                        </Typography>
                        <Typography variant="body1">
                            "{currentTranscript}"
                        </Typography>
                        <LinearProgress
                            variant="determinate"
                            value={confidence * 100}
                            sx={{ mt: 1 }}
                        />
                    </CardContent>
                </Card>
            )}

            {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ë“¤ */}
            <Box p={2}>
                <Box display="flex" gap={2} mb={2}>
                    <Button
                        variant={isListening ? 'contained' : 'outlined'}
                        startIcon={isListening ? <MicOffIcon /> : <MicIcon />}
                        onClick={isListening ? stopListening : startListening}
                        color={isListening ? 'error' : 'primary'}
                    >
                        {isListening ? 'ìŒì„± ì¸ì‹ ì¤‘ì§€' : 'ìŒì„± ì¸ì‹ ì‹œì‘'}
                    </Button>

                    <Button
                        variant="outlined"
                        startIcon={<SettingsIcon />}
                        onClick={() => setShowSettings(true)}
                    >
                        ì„¤ì •
                    </Button>
                </Box>

                {/* ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸ */}
                <Card sx={{ mb: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸
                        </Typography>
                        <TextField
                            fullWidth
                            multiline
                            rows={2}
                            value={testText}
                            onChange={(e) => setTestText(e.target.value)}
                            placeholder="ì½ì„ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
                            sx={{ mb: 2 }}
                        />
                        <Box display="flex" gap={1}>
                            <Button
                                variant="contained"
                                startIcon={<PlayIcon />}
                                onClick={() => speak(testText)}
                                disabled={isSpeaking}
                            >
                                ì¬ìƒ
                            </Button>
                            <Button
                                variant="outlined"
                                startIcon={<StopIcon />}
                                onClick={stopSpeaking}
                                disabled={!isSpeaking}
                            >
                                ì¤‘ì§€
                            </Button>
                        </Box>
                    </CardContent>
                </Card>

                {/* ìƒí™©ë³„ ì œì•ˆ */}
                <Card sx={{ mb: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ì¶”ì²œ ìŒì„± ëª…ë ¹
                        </Typography>
                        <Box display="flex" flexWrap="wrap" gap={1}>
                            {suggestions.map((suggestion, index) => (
                                <Chip
                                    key={index}
                                    label={suggestion}
                                    onClick={() => speak(`"${suggestion}" ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.`)}
                                    variant="outlined"
                                    size="small"
                                />
                            ))}
                        </Box>
                    </CardContent>
                </Card>

                {/* ìµœê·¼ ì„¸ì…˜ */}
                <Card>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ìµœê·¼ ìŒì„± ì¸ì‹ ê¸°ë¡
                        </Typography>
                        <List dense>
                            {sessions.slice(0, 5).map((session) => (
                                <ListItem key={session.id}>
                                    <ListItemIcon>
                                        <VoiceIcon />
                                    </ListItemIcon>
                                    <ListItemText
                                        primary={session.transcript}
                                        secondary={`ì‹ ë¢°ë„: ${Math.round(session.confidence * 100)}% | ${session.startTime.toLocaleTimeString()}`}
                                    />
                                </ListItem>
                            ))}
                        </List>
                    </CardContent>
                </Card>
            </Box>

            {/* ì„¤ì • ë‹¤ì´ì–¼ë¡œê·¸ */}
            <Dialog open={showSettings} onClose={() => setShowSettings(false)} maxWidth="md" fullWidth>
                <DialogTitle>ìŒì„± AI ì„¤ì •</DialogTitle>
                <DialogContent>
                    <Box display="flex" flexDirection="column" gap={3} pt={1}>
                        {/* ìŒì„± ì¸ì‹ ì„¤ì • */}
                        <Typography variant="h6">ìŒì„± ì¸ì‹</Typography>

                        <FormControl fullWidth>
                            <InputLabel>ì–¸ì–´</InputLabel>
                            <Select
                                value={settings.recognition.language}
                                label="ì–¸ì–´"
                                onChange={(e) => updateSettings({
                                    recognition: {
                                        ...settings.recognition,
                                        language: e.target.value as VoiceRecognitionLanguage
                                    }
                                })}
                            >
                                <MenuItem value="ko-KR">í•œêµ­ì–´</MenuItem>
                                <MenuItem value="en-US">English (US)</MenuItem>
                                <MenuItem value="ja-JP">æ—¥æœ¬èª</MenuItem>
                                <MenuItem value="zh-CN">ä¸­æ–‡</MenuItem>
                            </Select>
                        </FormControl>

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.recognition.continuous}
                                    onChange={(e) => updateSettings({
                                        recognition: {
                                            ...settings.recognition,
                                            continuous: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ì—°ì† ì¸ì‹"
                        />

                        <Box>
                            <Typography gutterBottom>ë¯¼ê°ë„</Typography>
                            <Slider
                                value={settings.recognition.sensitivity}
                                onChange={(_, value) => updateSettings({
                                    recognition: {
                                        ...settings.recognition,
                                        sensitivity: value as number
                                    }
                                })}
                                min={0.1}
                                max={1.0}
                                step={0.1}
                                marks={[
                                    { value: 0.3, label: 'ë‚®ìŒ' },
                                    { value: 0.7, label: 'ë³´í†µ' },
                                    { value: 1.0, label: 'ë†’ìŒ' }
                                ]}
                            />
                        </Box>

                        {/* ìŒì„± í•©ì„± ì„¤ì • */}
                        <Typography variant="h6">ìŒì„± í•©ì„±</Typography>

                        <FormControl fullWidth>
                            <InputLabel>ìŒì„±</InputLabel>
                            <Select
                                value={settings.synthesis.voice}
                                label="ìŒì„±"
                                onChange={(e) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        voice: e.target.value
                                    }
                                })}
                            >
                                {availableVoices
                                    .filter(voice => voice.lang.startsWith('ko'))
                                    .map(voice => (
                                        <MenuItem key={voice.name} value={voice.name}>
                                            {voice.name}
                                        </MenuItem>
                                    ))}
                            </Select>
                        </FormControl>

                        <Box>
                            <Typography gutterBottom>ì†ë„</Typography>
                            <Slider
                                value={settings.synthesis.rate}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        rate: value as number
                                    }
                                })}
                                min={0.5}
                                max={2.0}
                                step={0.1}
                                marks={[
                                    { value: 0.5, label: 'ëŠë¦¼' },
                                    { value: 1.0, label: 'ë³´í†µ' },
                                    { value: 2.0, label: 'ë¹ ë¦„' }
                                ]}
                            />
                        </Box>

                        <Box>
                            <Typography gutterBottom>ìŒë†’ì´</Typography>
                            <Slider
                                value={settings.synthesis.pitch}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        pitch: value as number
                                    }
                                })}
                                min={0.5}
                                max={2.0}
                                step={0.1}
                                marks={[
                                    { value: 0.5, label: 'ë‚®ìŒ' },
                                    { value: 1.0, label: 'ë³´í†µ' },
                                    { value: 2.0, label: 'ë†’ìŒ' }
                                ]}
                            />
                        </Box>

                        <Box>
                            <Typography gutterBottom>ë³¼ë¥¨</Typography>
                            <Slider
                                value={settings.synthesis.volume}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        volume: value as number
                                    }
                                })}
                                min={0.0}
                                max={1.0}
                                step={0.1}
                            />
                        </Box>

                        {/* AI ì„¤ì • */}
                        <Typography variant="h6">AI ê¸°ëŠ¥</Typography>

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.enableNLP}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            enableNLP: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ìì—°ì–´ ì²˜ë¦¬"
                        />

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.contextAware}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            contextAware: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ìƒí™© ì¸ì‹"
                        />

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.learningMode}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            learningMode: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="í•™ìŠµ ëª¨ë“œ"
                        />
                    </Box>
                </DialogContent>
                <DialogActions>
                    <Button onClick={() => setShowSettings(false)}>ì·¨ì†Œ</Button>
                    <Button variant="contained">ì €ì¥</Button>
                </DialogActions>
            </Dialog>
        </VoiceContainer>
    );
};

export default VoiceAIProvider;
