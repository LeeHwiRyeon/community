/**
 * üé§ ÏùåÏÑ± AI ÏãúÏä§ÌÖú
 * 
 * ÏùåÏÑ± Ïù∏Ïãù, ÏùåÏÑ± Î™ÖÎ†π, ÏùåÏÑ± Ìï©ÏÑ±ÏùÑ ÏßÄÏõêÌïòÎäî
 * Ìï∏Ï¶àÌîÑÎ¶¨ Ïª®ÌÖêÏ∏† Ï†úÏûë Î∞è Ï†úÏñ¥ ÏãúÏä§ÌÖú
 * 
 * @author AUTOAGENTS Manager
 * @version 3.0.0
 * @created 2025-10-02
 */

import React, {
    useState,
    useEffect,
    useCallback,
    useRef,
    createContext,
    useContext,
    ReactNode
} from 'react';
import {
    Box,
    Paper,
    Typography,
    Button,
    IconButton,
    Card,
    CardContent,
    Dialog,
    DialogTitle,
    DialogContent,
    DialogActions,
    TextField,
    Slider,
    FormControl,
    InputLabel,
    Select,
    MenuItem,
    Chip,
    List,
    ListItem,
    ListItemText,
    ListItemIcon,
    ListItemSecondaryAction,
    Avatar,
    LinearProgress,
    Alert,
    Tooltip,
    Switch,
    FormControlLabel,
    useTheme
} from '@mui/material';
import {
    Mic as MicIcon,
    MicOff as MicOffIcon,
    VolumeUp as VolumeUpIcon,
    VolumeOff as VolumeOffIcon,
    RecordVoiceOver as VoiceIcon,
    Hearing as HearingIcon,
    Translate as TranslateIcon,
    Settings as SettingsIcon,
    PlayArrow as PlayIcon,
    Pause as PauseIcon,
    Stop as StopIcon,
    Save as SaveIcon,
    Delete as DeleteIcon,
    Edit as EditIcon,
    Add as AddIcon,
    Psychology as AIIcon,
    GraphicEq as WaveformIcon,
    GraphicEq as EqualizerIcon,
    Speed as SpeedIcon,
    Tune as TuneIcon
} from '@mui/icons-material';
import { styled, keyframes } from '@mui/system';

// Web Speech API ÌÉÄÏûÖ Ï†ïÏùò
declare global {
    interface Window {
        SpeechRecognition: any;
        webkitSpeechRecognition: any;
    }
}

interface SpeechRecognition {
    continuous: boolean;
    interimResults: boolean;
    lang: string;
    onresult: (event: any) => void;
    onerror: (event: any) => void;
    onstart: () => void;
    onend: () => void;
    start: () => void;
    stop: () => void;
}

// ÏùåÏÑ± AI ÌÉÄÏûÖ Ï†ïÏùò
export type VoiceCommand = {
    id: string;
    trigger: string[];
    action: string;
    description: string;
    category: 'navigation' | 'editing' | 'creation' | 'system' | 'custom';
    parameters?: Record<string, any>;
    enabled: boolean;
};

export type VoiceRecognitionLanguage = 'ko-KR' | 'en-US' | 'ja-JP' | 'zh-CN' | 'es-ES' | 'fr-FR';

export interface VoiceSettings {
    recognition: {
        language: VoiceRecognitionLanguage;
        continuous: boolean;
        interimResults: boolean;
        maxAlternatives: number;
        sensitivity: number;
        noiseReduction: boolean;
    };
    synthesis: {
        voice: string;
        rate: number;
        pitch: number;
        volume: number;
        language: string;
    };
    commands: {
        wakeWord: string;
        confirmationRequired: boolean;
        timeout: number;
        customCommands: VoiceCommand[];
    };
    ai: {
        enableNLP: boolean;
        contextAware: boolean;
        learningMode: boolean;
        personalizedResponses: boolean;
    };
}

export interface VoiceSession {
    id: string;
    startTime: Date;
    endTime?: Date;
    transcript: string;
    confidence: number;
    commands: string[];
    language: VoiceRecognitionLanguage;
    duration: number;
}

interface VoiceAIContextValue {
    isListening: boolean;
    isSpeaking: boolean;
    currentTranscript: string;
    confidence: number;
    sessions: VoiceSession[];
    settings: VoiceSettings;
    availableVoices: SpeechSynthesisVoice[];

    // ÏùåÏÑ± Ïù∏Ïãù
    startListening: () => void;
    stopListening: () => void;

    // ÏùåÏÑ± Ìï©ÏÑ±
    speak: (text: string, options?: Partial<VoiceSettings['synthesis']>) => void;
    stopSpeaking: () => void;

    // Î™ÖÎ†π Ï≤òÎ¶¨
    executeCommand: (command: string) => void;
    addCustomCommand: (command: VoiceCommand) => void;
    removeCustomCommand: (commandId: string) => void;

    // ÏÑ§Ï†ï
    updateSettings: (newSettings: Partial<VoiceSettings>) => void;

    // AI Í∏∞Îä•
    processNaturalLanguage: (text: string) => Promise<string>;
    getContextualSuggestions: () => string[];
}

// Í∏∞Î≥∏ ÏÑ§Ï†ï
const DEFAULT_VOICE_SETTINGS: VoiceSettings = {
    recognition: {
        language: 'ko-KR',
        continuous: true,
        interimResults: true,
        maxAlternatives: 3,
        sensitivity: 0.7,
        noiseReduction: true
    },
    synthesis: {
        voice: '',
        rate: 1.0,
        pitch: 1.0,
        volume: 0.8,
        language: 'ko-KR'
    },
    commands: {
        wakeWord: 'ÏïàÎÖï ÏóêÏù¥Ï†ÑÌä∏',
        confirmationRequired: false,
        timeout: 5000,
        customCommands: []
    },
    ai: {
        enableNLP: true,
        contextAware: true,
        learningMode: true,
        personalizedResponses: true
    }
};

// Í∏∞Î≥∏ ÏùåÏÑ± Î™ÖÎ†πÎì§
const DEFAULT_COMMANDS: VoiceCommand[] = [
    {
        id: 'create-post',
        trigger: ['ÏÉà Í∏Ä ÏûëÏÑ±', 'Ìè¨Ïä§Ìä∏ ÎßåÎì§Í∏∞', 'Í∏ÄÏì∞Í∏∞ ÏãúÏûë'],
        action: 'CREATE_POST',
        description: 'ÏÉàÎ°úÏö¥ Í∏ÄÏùÑ ÏûëÏÑ±Ìï©ÎãàÎã§',
        category: 'creation',
        enabled: true
    },
    {
        id: 'save-content',
        trigger: ['Ï†ÄÏû•', 'Ï†ÄÏû•Ìï¥Ï§ò', 'ÏÑ∏Ïù¥Î∏å'],
        action: 'SAVE_CONTENT',
        description: 'ÌòÑÏû¨ ÎÇ¥Ïö©ÏùÑ Ï†ÄÏû•Ìï©ÎãàÎã§',
        category: 'editing',
        enabled: true
    },
    {
        id: 'navigate-home',
        trigger: ['ÌôàÏúºÎ°ú', 'Î©îÏù∏ÏúºÎ°ú', 'Ï≤òÏùåÏúºÎ°ú'],
        action: 'NAVIGATE_HOME',
        description: 'Ìôà ÌéòÏù¥ÏßÄÎ°ú Ïù¥ÎèôÌï©ÎãàÎã§',
        category: 'navigation',
        enabled: true
    },
    {
        id: 'toggle-dark-mode',
        trigger: ['Îã§ÌÅ¨Î™®Îìú', 'Ïñ¥ÎëêÏö¥ ÌÖåÎßà', 'Î∞ùÏùÄ ÌÖåÎßà'],
        action: 'TOGGLE_THEME',
        description: 'ÌÖåÎßàÎ•º Î≥ÄÍ≤ΩÌï©ÎãàÎã§',
        category: 'system',
        enabled: true
    },
    {
        id: 'read-content',
        trigger: ['ÏùΩÏñ¥Ï§ò', 'ÏùΩÍ∏∞', 'ÏùåÏÑ±ÏúºÎ°ú ÏùΩÍ∏∞'],
        action: 'READ_CONTENT',
        description: 'ÌòÑÏû¨ ÎÇ¥Ïö©ÏùÑ ÏùåÏÑ±ÏúºÎ°ú ÏùΩÏñ¥Ï§çÎãàÎã§',
        category: 'system',
        enabled: true
    }
];

// Ïï†ÎãàÎ©îÏù¥ÏÖò
const pulseAnimation = keyframes`
    0% { transform: scale(1); opacity: 1; }
    50% { transform: scale(1.1); opacity: 0.7; }
    100% { transform: scale(1); opacity: 1; }
`;

const waveAnimation = keyframes`
    0%, 100% { height: 20px; }
    25% { height: 40px; }
    50% { height: 60px; }
    75% { height: 30px; }
`;

// Ïä§ÌÉÄÏùºÎìú Ïª¥Ìè¨ÎÑåÌä∏
const VoiceContainer = styled(Paper)(({ theme }) => ({
    height: '100%',
    display: 'flex',
    flexDirection: 'column',
    overflow: 'hidden'
}));

const VoiceVisualizer = styled(Box)<{ isActive: boolean }>(({ theme, isActive }) => ({
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    height: 100,
    backgroundColor: theme.palette.background.default,
    borderRadius: theme.shape.borderRadius,
    margin: theme.spacing(2),
    position: 'relative',

    '&::before': {
        content: '""',
        position: 'absolute',
        width: '100%',
        height: '100%',
        borderRadius: theme.shape.borderRadius,
        background: isActive ?
            `radial-gradient(circle, ${theme.palette.primary.light}20 0%, transparent 70%)` :
            'transparent',
        animation: isActive ? `${pulseAnimation} 2s infinite` : 'none'
    }
}));

const WaveBar = styled(Box)<{ isActive: boolean; delay: number }>(({ theme, isActive, delay }) => ({
    width: 4,
    backgroundColor: theme.palette.primary.main,
    margin: '0 2px',
    borderRadius: 2,
    animation: isActive ? `${waveAnimation} 1s infinite ${delay}s` : 'none',
    height: isActive ? 20 : 10,
    transition: 'height 0.3s ease'
}));

const CommandChip = styled(Chip)<{ category: VoiceCommand['category'] }>(({ theme, category }) => ({
    backgroundColor:
        category === 'navigation' ? theme.palette.info.light :
            category === 'editing' ? theme.palette.success.light :
                category === 'creation' ? theme.palette.primary.light :
                    category === 'system' ? theme.palette.warning.light :
                        theme.palette.grey[300],
    margin: theme.spacing(0.5)
}));

// ÏùåÏÑ± AI Ïª®ÌÖçÏä§Ìä∏
const VoiceAIContext = createContext<VoiceAIContextValue | undefined>(undefined);

// Ïª§Ïä§ÌÖÄ ÌõÖ
export const useVoiceAI = (): VoiceAIContextValue => {
    const context = useContext(VoiceAIContext);
    if (!context) {
        throw new Error('useVoiceAI must be used within VoiceAIProvider');
    }
    return context;
};

// ÏùåÏÑ± Ïù∏Ïãù ÌõÖ
const useSpeechRecognition = () => {
    const [isListening, setIsListening] = useState(false);
    const [transcript, setTranscript] = useState('');
    const [confidence, setConfidence] = useState(0);
    const recognitionRef = useRef<SpeechRecognition | null>(null);

    useEffect(() => {
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
            recognitionRef.current = new SpeechRecognition();
        }
    }, []);

    const startListening = useCallback((settings: VoiceSettings['recognition']) => {
        if (!recognitionRef.current) return;

        const recognition = recognitionRef.current;
        recognition.continuous = settings.continuous;
        recognition.interimResults = settings.interimResults;
        recognition.lang = settings.language;
        // recognition.maxAlternatives = settings.maxAlternatives; // Property not available in all browsers

        recognition.onstart = () => setIsListening(true);
        recognition.onend = () => setIsListening(false);

        recognition.onresult = (event) => {
            let finalTranscript = '';
            let interimTranscript = '';

            for (let i = event.resultIndex; i < event.results.length; i++) {
                const result = event.results[i];
                if (result.isFinal) {
                    finalTranscript += result[0].transcript;
                    setConfidence(result[0].confidence);
                } else {
                    interimTranscript += result[0].transcript;
                }
            }

            setTranscript(finalTranscript || interimTranscript);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            setIsListening(false);
        };

        recognition.start();
    }, []);

    const stopListening = useCallback(() => {
        if (recognitionRef.current) {
            recognitionRef.current.stop();
        }
    }, []);

    return { isListening, transcript, confidence, startListening, stopListening };
};

// ÏùåÏÑ± Ìï©ÏÑ± ÌõÖ
const useSpeechSynthesis = () => {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [availableVoices, setAvailableVoices] = useState<SpeechSynthesisVoice[]>([]);

    useEffect(() => {
        const updateVoices = () => {
            setAvailableVoices(speechSynthesis.getVoices());
        };

        updateVoices();
        speechSynthesis.addEventListener('voiceschanged', updateVoices);

        return () => {
            speechSynthesis.removeEventListener('voiceschanged', updateVoices);
        };
    }, []);

    const speak = useCallback((text: string, options: Partial<VoiceSettings['synthesis']> = {}) => {
        if (!text) return;

        const utterance = new SpeechSynthesisUtterance(text);

        if (options.voice) {
            const voice = availableVoices.find(v => v.name === options.voice);
            if (voice) utterance.voice = voice;
        }

        utterance.rate = options.rate || 1.0;
        utterance.pitch = options.pitch || 1.0;
        utterance.volume = options.volume || 0.8;
        utterance.lang = options.language || 'ko-KR';

        utterance.onstart = () => setIsSpeaking(true);
        utterance.onend = () => setIsSpeaking(false);
        utterance.onerror = () => setIsSpeaking(false);

        speechSynthesis.speak(utterance);
    }, [availableVoices]);

    const stopSpeaking = useCallback(() => {
        speechSynthesis.cancel();
        setIsSpeaking(false);
    }, []);

    return { isSpeaking, availableVoices, speak, stopSpeaking };
};

// ÏùåÏÑ± AI ÌîÑÎ°úÎ∞îÏù¥Îçî
interface VoiceAIProviderProps {
    children: ReactNode;
}

export const VoiceAIProvider: React.FC<VoiceAIProviderProps> = ({ children }) => {
    const [settings, setSettings] = useState<VoiceSettings>(() => {
        try {
            const saved = localStorage.getItem('voice-ai-settings');
            return saved ? { ...DEFAULT_VOICE_SETTINGS, ...JSON.parse(saved) } : DEFAULT_VOICE_SETTINGS;
        } catch {
            return DEFAULT_VOICE_SETTINGS;
        }
    });

    const [sessions, setSessions] = useState<VoiceSession[]>([]);
    const [commands, setCommands] = useState<VoiceCommand[]>(DEFAULT_COMMANDS);

    const speechRecognition = useSpeechRecognition();
    const speechSynthesis = useSpeechSynthesis();

    // Î™ÖÎ†π Ïã§Ìñâ
    const executeCommand = useCallback((commandText: string) => {
        const matchedCommand = commands.find(cmd =>
            cmd.enabled && cmd.trigger.some(trigger =>
                commandText.toLowerCase().includes(trigger.toLowerCase())
            )
        );

        if (matchedCommand) {
            console.log('Executing command:', matchedCommand.action);

            switch (matchedCommand.action) {
                case 'CREATE_POST':
                    // ÏÉà Í∏Ä ÏûëÏÑ± Î°úÏßÅ
                    speechSynthesis.speak('ÏÉàÎ°úÏö¥ Í∏Ä ÏûëÏÑ±ÏùÑ ÏãúÏûëÌï©ÎãàÎã§.');
                    break;

                case 'SAVE_CONTENT':
                    // Ï†ÄÏû• Î°úÏßÅ
                    speechSynthesis.speak('ÎÇ¥Ïö©ÏùÑ Ï†ÄÏû•ÌñàÏäµÎãàÎã§.');
                    break;

                case 'NAVIGATE_HOME':
                    // Ìôà Ïù¥Îèô Î°úÏßÅ
                    speechSynthesis.speak('Ìôà ÌéòÏù¥ÏßÄÎ°ú Ïù¥ÎèôÌï©ÎãàÎã§.');
                    break;

                case 'TOGGLE_THEME':
                    // ÌÖåÎßà Î≥ÄÍ≤Ω Î°úÏßÅ
                    speechSynthesis.speak('ÌÖåÎßàÎ•º Î≥ÄÍ≤ΩÌñàÏäµÎãàÎã§.');
                    break;

                case 'READ_CONTENT':
                    // Ïª®ÌÖêÏ∏† ÏùΩÍ∏∞ Î°úÏßÅ
                    const content = document.querySelector('main')?.textContent || 'ÏùΩÏùÑ ÎÇ¥Ïö©Ïù¥ ÏóÜÏäµÎãàÎã§.';
                    speechSynthesis.speak(content.substring(0, 500));
                    break;

                default:
                    speechSynthesis.speak('Î™ÖÎ†πÏùÑ Ïã§ÌñâÌñàÏäµÎãàÎã§.');
            }
        } else {
            speechSynthesis.speak('Ïù∏ÏãùÎêú Î™ÖÎ†πÏù¥ ÏóÜÏäµÎãàÎã§.');
        }
    }, [commands, speechSynthesis]);

    // ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨ (Î™®Ïùò AI)
    const processNaturalLanguage = useCallback(async (text: string): Promise<string> => {
        // Ïã§Ï†úÎ°úÎäî AI API Ìò∏Ï∂ú
        await new Promise(resolve => setTimeout(resolve, 1000));

        if (text.includes('ÏïàÎÖï') || text.includes('hello')) {
            return 'ÏïàÎÖïÌïòÏÑ∏Ïöî! Î¨¥ÏóáÏùÑ ÎèÑÏôÄÎìúÎ¶¥ÍπåÏöî?';
        } else if (text.includes('ÎèÑÏõÄ') || text.includes('help')) {
            return 'ÏùåÏÑ± Î™ÖÎ†πÏúºÎ°ú Í∏Ä ÏûëÏÑ±, Ï†ÄÏû•, ÎÑ§ÎπÑÍ≤åÏù¥ÏÖò Îì±ÏùÑ Ìï† Ïàò ÏûàÏäµÎãàÎã§.';
        } else if (text.includes('Î™ÖÎ†π') || text.includes('command')) {
            return `ÏÇ¨Ïö© Í∞ÄÎä•Ìïú Î™ÖÎ†π: ${commands.map(c => c.trigger[0]).join(', ')}`;
        } else {
            return 'Ï£ÑÏÜ°Ìï©ÎãàÎã§. Ïù¥Ìï¥ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. Îã§Ïãú ÎßêÏîÄÌï¥ Ï£ºÏÑ∏Ïöî.';
        }
    }, [commands]);

    // ÏÉÅÌô©Î≥Ñ Ï†úÏïà
    const getContextualSuggestions = useCallback((): string[] => {
        const currentPath = window.location.pathname;

        if (currentPath.includes('write') || currentPath.includes('edit')) {
            return ['Ï†ÄÏû•Ìï¥Ï§ò', 'ÏùΩÏñ¥Ï§ò', 'ÎßûÏ∂§Î≤ï Í≤ÄÏÇ¨'];
        } else if (currentPath.includes('home')) {
            return ['ÏÉà Í∏Ä ÏûëÏÑ±', 'ÏµúÍ∑º Í∏Ä Î≥¥Í∏∞', 'ÏÑ§Ï†ï Ïó¥Í∏∞'];
        } else {
            return ['ÌôàÏúºÎ°ú', 'Îí§Î°úÍ∞ÄÍ∏∞', 'ÎèÑÏõÄÎßê'];
        }
    }, []);

    // ÏùåÏÑ± Ïù∏Ïãù ÏãúÏûë
    const startListening = useCallback(() => {
        speechRecognition.startListening(settings.recognition);
    }, [speechRecognition, settings.recognition]);

    // ÏùåÏÑ± Ïù∏Ïãù Ï§ëÏßÄ
    const stopListening = useCallback(() => {
        speechRecognition.stopListening();
    }, [speechRecognition]);

    // ÏùåÏÑ± Ìï©ÏÑ±
    const speak = useCallback((text: string, options?: Partial<VoiceSettings['synthesis']>) => {
        speechSynthesis.speak(text, { ...settings.synthesis, ...options });
    }, [speechSynthesis, settings.synthesis]);

    // ÏùåÏÑ± Ìï©ÏÑ± Ï§ëÏßÄ
    const stopSpeaking = useCallback(() => {
        speechSynthesis.stopSpeaking();
    }, [speechSynthesis]);

    // Ïª§Ïä§ÌÖÄ Î™ÖÎ†π Ï∂îÍ∞Ä
    const addCustomCommand = useCallback((command: VoiceCommand) => {
        setCommands(prev => [...prev, command]);
    }, []);

    // Ïª§Ïä§ÌÖÄ Î™ÖÎ†π Ï†úÍ±∞
    const removeCustomCommand = useCallback((commandId: string) => {
        setCommands(prev => prev.filter(cmd => cmd.id !== commandId));
    }, []);

    // ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
    const updateSettings = useCallback((newSettings: Partial<VoiceSettings>) => {
        setSettings(prev => {
            const updated = { ...prev, ...newSettings };
            localStorage.setItem('voice-ai-settings', JSON.stringify(updated));
            return updated;
        });
    }, []);

    // ÏùåÏÑ± Ïù∏Ïãù Í≤∞Í≥º Ï≤òÎ¶¨
    useEffect(() => {
        if (speechRecognition.transcript && speechRecognition.confidence > 0.5) {
            const transcript = speechRecognition.transcript.trim();

            // Ïõ®Ïù¥ÌÅ¨ ÏõåÎìú Ï≤¥ÌÅ¨
            if (transcript.toLowerCase().includes(settings.commands.wakeWord.toLowerCase())) {
                executeCommand(transcript);
            }

            // ÏÑ∏ÏÖò Í∏∞Î°ù
            const session: VoiceSession = {
                id: `session-${Date.now()}`,
                startTime: new Date(),
                transcript,
                confidence: speechRecognition.confidence,
                commands: [transcript],
                language: settings.recognition.language,
                duration: 0
            };

            setSessions(prev => [session, ...prev.slice(0, 49)]);
        }
    }, [speechRecognition.transcript, speechRecognition.confidence, settings.commands.wakeWord, executeCommand]);

    const contextValue: VoiceAIContextValue = {
        isListening: speechRecognition.isListening,
        isSpeaking: speechSynthesis.isSpeaking,
        currentTranscript: speechRecognition.transcript,
        confidence: speechRecognition.confidence,
        sessions,
        settings,
        availableVoices: speechSynthesis.availableVoices,
        startListening,
        stopListening,
        speak,
        stopSpeaking,
        executeCommand,
        addCustomCommand,
        removeCustomCommand,
        updateSettings,
        processNaturalLanguage,
        getContextualSuggestions
    };

    return (
        <VoiceAIContext.Provider value={contextValue}>
            {children}
        </VoiceAIContext.Provider>
    );
};

// ÏùåÏÑ± Ïª®Ìä∏Î°§ Ìå®ÎÑê
export const VoiceControlPanel: React.FC = () => {
    const {
        isListening,
        isSpeaking,
        currentTranscript,
        confidence,
        sessions,
        settings,
        availableVoices,
        startListening,
        stopListening,
        speak,
        stopSpeaking,
        updateSettings,
        getContextualSuggestions
    } = useVoiceAI();

    const [showSettings, setShowSettings] = useState(false);
    const [testText, setTestText] = useState('ÏïàÎÖïÌïòÏÑ∏Ïöî! ÏùåÏÑ± Ìï©ÏÑ± ÌÖåÏä§Ìä∏ÏûÖÎãàÎã§.');

    const theme = useTheme();
    const suggestions = getContextualSuggestions();

    return (
        <VoiceContainer>
            {/* Ìó§Îçî */}
            <Box p={2} borderBottom={1} borderColor="divider">
                <Box display="flex" justifyContent="space-between" alignItems="center">
                    <Typography variant="h6">ÏùåÏÑ± AI ÏãúÏä§ÌÖú</Typography>
                    <Box display="flex" gap={1}>
                        <Chip
                            icon={<MicIcon />}
                            label={isListening ? 'Îì£Îäî Ï§ë' : 'ÎåÄÍ∏∞ Ï§ë'}
                            color={isListening ? 'success' : 'default'}
                        />
                        <Chip
                            icon={<VolumeUpIcon />}
                            label={isSpeaking ? 'ÎßêÌïòÎäî Ï§ë' : 'Ï°∞Ïö©Ìï®'}
                            color={isSpeaking ? 'primary' : 'default'}
                        />
                    </Box>
                </Box>
            </Box>

            {/* ÏùåÏÑ± ÏãúÍ∞ÅÌôî */}
            <VoiceVisualizer isActive={isListening || isSpeaking}>
                <Box display="flex" alignItems="center" gap={0.5}>
                    {Array.from({ length: 20 }, (_, i) => (
                        <WaveBar
                            key={i}
                            isActive={isListening || isSpeaking}
                            delay={i * 0.1}
                        />
                    ))}
                </Box>

                <IconButton
                    sx={{
                        position: 'absolute',
                        width: 60,
                        height: 60,
                        backgroundColor: isListening ? 'error.main' : 'primary.main',
                        color: 'white',
                        '&:hover': {
                            backgroundColor: isListening ? 'error.dark' : 'primary.dark'
                        }
                    }}
                    onClick={isListening ? stopListening : startListening}
                >
                    {isListening ? <MicOffIcon /> : <MicIcon />}
                </IconButton>
            </VoiceVisualizer>

            {/* ÌòÑÏû¨ Ïù∏Ïãù Í≤∞Í≥º */}
            {currentTranscript && (
                <Card sx={{ m: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            Ïù∏ÏãùÎêú ÏùåÏÑ± (Ïã†Î¢∞ÎèÑ: {Math.round(confidence * 100)}%)
                        </Typography>
                        <Typography variant="body1">
                            "{currentTranscript}"
                        </Typography>
                        <LinearProgress
                            variant="determinate"
                            value={confidence * 100}
                            sx={{ mt: 1 }}
                        />
                    </CardContent>
                </Card>
            )}

            {/* Ïª®Ìä∏Î°§ Î≤ÑÌäºÎì§ */}
            <Box p={2}>
                <Box display="flex" gap={2} mb={2}>
                    <Button
                        variant={isListening ? 'contained' : 'outlined'}
                        startIcon={isListening ? <MicOffIcon /> : <MicIcon />}
                        onClick={isListening ? stopListening : startListening}
                        color={isListening ? 'error' : 'primary'}
                    >
                        {isListening ? 'ÏùåÏÑ± Ïù∏Ïãù Ï§ëÏßÄ' : 'ÏùåÏÑ± Ïù∏Ïãù ÏãúÏûë'}
                    </Button>

                    <Button
                        variant="outlined"
                        startIcon={<SettingsIcon />}
                        onClick={() => setShowSettings(true)}
                    >
                        ÏÑ§Ï†ï
                    </Button>
                </Box>

                {/* ÏùåÏÑ± Ìï©ÏÑ± ÌÖåÏä§Ìä∏ */}
                <Card sx={{ mb: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ÏùåÏÑ± Ìï©ÏÑ± ÌÖåÏä§Ìä∏
                        </Typography>
                        <TextField
                            fullWidth
                            multiline
                            rows={2}
                            value={testText}
                            onChange={(e) => setTestText(e.target.value)}
                            placeholder="ÏùΩÏùÑ ÌÖçÏä§Ìä∏Î•º ÏûÖÎ†•ÌïòÏÑ∏Ïöî..."
                            sx={{ mb: 2 }}
                        />
                        <Box display="flex" gap={1}>
                            <Button
                                variant="contained"
                                startIcon={<PlayIcon />}
                                onClick={() => speak(testText)}
                                disabled={isSpeaking}
                            >
                                Ïû¨ÏÉù
                            </Button>
                            <Button
                                variant="outlined"
                                startIcon={<StopIcon />}
                                onClick={stopSpeaking}
                                disabled={!isSpeaking}
                            >
                                Ï§ëÏßÄ
                            </Button>
                        </Box>
                    </CardContent>
                </Card>

                {/* ÏÉÅÌô©Î≥Ñ Ï†úÏïà */}
                <Card sx={{ mb: 2 }}>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            Ï∂îÏ≤ú ÏùåÏÑ± Î™ÖÎ†π
                        </Typography>
                        <Box display="flex" flexWrap="wrap" gap={1}>
                            {suggestions.map((suggestion, index) => (
                                <Chip
                                    key={index}
                                    label={suggestion}
                                    onClick={() => speak(`"${suggestion}" Î™ÖÎ†πÏùÑ Ïã§ÌñâÌï©ÎãàÎã§.`)}
                                    variant="outlined"
                                    size="small"
                                />
                            ))}
                        </Box>
                    </CardContent>
                </Card>

                {/* ÏµúÍ∑º ÏÑ∏ÏÖò */}
                <Card>
                    <CardContent>
                        <Typography variant="subtitle2" gutterBottom>
                            ÏµúÍ∑º ÏùåÏÑ± Ïù∏Ïãù Í∏∞Î°ù
                        </Typography>
                        <List dense>
                            {sessions.slice(0, 5).map((session) => (
                                <ListItem key={session.id}>
                                    <ListItemIcon>
                                        <VoiceIcon />
                                    </ListItemIcon>
                                    <ListItemText
                                        primary={session.transcript}
                                        secondary={`Ïã†Î¢∞ÎèÑ: ${Math.round(session.confidence * 100)}% | ${session.startTime.toLocaleTimeString()}`}
                                    />
                                </ListItem>
                            ))}
                        </List>
                    </CardContent>
                </Card>
            </Box>

            {/* ÏÑ§Ï†ï Îã§Ïù¥ÏñºÎ°úÍ∑∏ */}
            <Dialog open={showSettings} onClose={() => setShowSettings(false)} maxWidth="md" fullWidth>
                <DialogTitle>ÏùåÏÑ± AI ÏÑ§Ï†ï</DialogTitle>
                <DialogContent>
                    <Box display="flex" flexDirection="column" gap={3} pt={1}>
                        {/* ÏùåÏÑ± Ïù∏Ïãù ÏÑ§Ï†ï */}
                        <Typography variant="h6">ÏùåÏÑ± Ïù∏Ïãù</Typography>

                        <FormControl fullWidth>
                            <InputLabel>Ïñ∏Ïñ¥</InputLabel>
                            <Select
                                value={settings.recognition.language}
                                label="Ïñ∏Ïñ¥"
                                onChange={(e) => updateSettings({
                                    recognition: {
                                        ...settings.recognition,
                                        language: e.target.value as VoiceRecognitionLanguage
                                    }
                                })}
                            >
                                <MenuItem value="ko-KR">ÌïúÍµ≠Ïñ¥</MenuItem>
                                <MenuItem value="en-US">English (US)</MenuItem>
                                <MenuItem value="ja-JP">Êó•Êú¨Ë™û</MenuItem>
                                <MenuItem value="zh-CN">‰∏≠Êñá</MenuItem>
                            </Select>
                        </FormControl>

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.recognition.continuous}
                                    onChange={(e) => updateSettings({
                                        recognition: {
                                            ...settings.recognition,
                                            continuous: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="Ïó∞ÏÜç Ïù∏Ïãù"
                        />

                        <Box>
                            <Typography gutterBottom>ÎØºÍ∞êÎèÑ</Typography>
                            <Slider
                                value={settings.recognition.sensitivity}
                                onChange={(_, value) => updateSettings({
                                    recognition: {
                                        ...settings.recognition,
                                        sensitivity: value as number
                                    }
                                })}
                                min={0.1}
                                max={1.0}
                                step={0.1}
                                marks={[
                                    { value: 0.3, label: 'ÎÇÆÏùå' },
                                    { value: 0.7, label: 'Î≥¥ÌÜµ' },
                                    { value: 1.0, label: 'ÎÜíÏùå' }
                                ]}
                            />
                        </Box>

                        {/* ÏùåÏÑ± Ìï©ÏÑ± ÏÑ§Ï†ï */}
                        <Typography variant="h6">ÏùåÏÑ± Ìï©ÏÑ±</Typography>

                        <FormControl fullWidth>
                            <InputLabel>ÏùåÏÑ±</InputLabel>
                            <Select
                                value={settings.synthesis.voice}
                                label="ÏùåÏÑ±"
                                onChange={(e) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        voice: e.target.value
                                    }
                                })}
                            >
                                {availableVoices
                                    .filter(voice => voice.lang.startsWith('ko'))
                                    .map(voice => (
                                        <MenuItem key={voice.name} value={voice.name}>
                                            {voice.name}
                                        </MenuItem>
                                    ))}
                            </Select>
                        </FormControl>

                        <Box>
                            <Typography gutterBottom>ÏÜçÎèÑ</Typography>
                            <Slider
                                value={settings.synthesis.rate}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        rate: value as number
                                    }
                                })}
                                min={0.5}
                                max={2.0}
                                step={0.1}
                                marks={[
                                    { value: 0.5, label: 'ÎäêÎ¶º' },
                                    { value: 1.0, label: 'Î≥¥ÌÜµ' },
                                    { value: 2.0, label: 'Îπ†Î¶Ñ' }
                                ]}
                            />
                        </Box>

                        <Box>
                            <Typography gutterBottom>ÏùåÎÜíÏù¥</Typography>
                            <Slider
                                value={settings.synthesis.pitch}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        pitch: value as number
                                    }
                                })}
                                min={0.5}
                                max={2.0}
                                step={0.1}
                                marks={[
                                    { value: 0.5, label: 'ÎÇÆÏùå' },
                                    { value: 1.0, label: 'Î≥¥ÌÜµ' },
                                    { value: 2.0, label: 'ÎÜíÏùå' }
                                ]}
                            />
                        </Box>

                        <Box>
                            <Typography gutterBottom>Î≥ºÎ•®</Typography>
                            <Slider
                                value={settings.synthesis.volume}
                                onChange={(_, value) => updateSettings({
                                    synthesis: {
                                        ...settings.synthesis,
                                        volume: value as number
                                    }
                                })}
                                min={0.0}
                                max={1.0}
                                step={0.1}
                            />
                        </Box>

                        {/* AI ÏÑ§Ï†ï */}
                        <Typography variant="h6">AI Í∏∞Îä•</Typography>

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.enableNLP}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            enableNLP: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨"
                        />

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.contextAware}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            contextAware: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ÏÉÅÌô© Ïù∏Ïãù"
                        />

                        <FormControlLabel
                            control={
                                <Switch
                                    checked={settings.ai.learningMode}
                                    onChange={(e) => updateSettings({
                                        ai: {
                                            ...settings.ai,
                                            learningMode: e.target.checked
                                        }
                                    })}
                                />
                            }
                            label="ÌïôÏäµ Î™®Îìú"
                        />
                    </Box>
                </DialogContent>
                <DialogActions>
                    <Button onClick={() => setShowSettings(false)}>Ï∑®ÏÜå</Button>
                    <Button variant="contained">Ï†ÄÏû•</Button>
                </DialogActions>
            </Dialog>
        </VoiceContainer>
    );
};

export default VoiceAIProvider;
