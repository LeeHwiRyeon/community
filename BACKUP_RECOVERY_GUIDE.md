# ë°±ì—… & ë³µêµ¬ ì „ëµ ê°€ì´ë“œ (Backup & Recovery Strategy)

## ğŸ“‹ ëª©ì°¨
- [1. ê°œìš”](#1-ê°œìš”)
- [2. ë°±ì—… ì „ëµ](#2-ë°±ì—…-ì „ëµ)
- [3. ìë™ ë°±ì—… ì‹œìŠ¤í…œ](#3-ìë™-ë°±ì—…-ì‹œìŠ¤í…œ)
- [4. ë°ì´í„° ë³µêµ¬ ì ˆì°¨](#4-ë°ì´í„°-ë³µêµ¬-ì ˆì°¨)
- [5. ì¬í•´ ë³µêµ¬ ê³„íš (DRP)](#5-ì¬í•´-ë³µêµ¬-ê³„íš-drp)
- [6. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦](#6-ë°ì´í„°-ë¬´ê²°ì„±-ê²€ì¦)
- [7. ë°±ì—… ëª¨ë‹ˆí„°ë§](#7-ë°±ì—…-ëª¨ë‹ˆí„°ë§)
- [8. ë³µêµ¬ í…ŒìŠ¤íŠ¸](#8-ë³µêµ¬-í…ŒìŠ¤íŠ¸)
- [9. ì²´í¬ë¦¬ìŠ¤íŠ¸](#9-ì²´í¬ë¦¬ìŠ¤íŠ¸)
- [10. êµ¬í˜„ ë¡œë“œë§µ](#10-êµ¬í˜„-ë¡œë“œë§µ)

---

## 1. ê°œìš”

### 1.1 ëª©í‘œ

ë°ì´í„° ì†ì‹¤ì„ ë°©ì§€í•˜ê³  ì¬í•´ ë°œìƒ ì‹œ ë¹ ë¥¸ ë³µêµ¬ë¥¼ ë³´ì¥í•˜ëŠ” ì¢…í•©ì ì¸ ë°±ì—… & ë³µêµ¬ ì‹œìŠ¤í…œ êµ¬ì¶•

### 1.2 í•µì‹¬ ì§€í‘œ

| ì§€í‘œ                               | ëª©í‘œ   | ì„¤ëª…                         |
| ---------------------------------- | ------ | ---------------------------- |
| **RPO** (Recovery Point Objective) | 1ì‹œê°„  | í—ˆìš© ê°€ëŠ¥í•œ ìµœëŒ€ ë°ì´í„° ì†ì‹¤ |
| **RTO** (Recovery Time Objective)  | 4ì‹œê°„  | ëª©í‘œ ë³µêµ¬ ì‹œê°„               |
| **ë°±ì—… ë¹ˆë„**                      | ì¼ 4íšŒ | ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì£¼ê¸°       |
| **ë°±ì—… ë³´ê´€**                      | 30ì¼   | ë°±ì—… ë°ì´í„° ë³´ê´€ ê¸°ê°„        |
| **ë³µêµ¬ ì„±ê³µë¥ **                    | 99.9%  | ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥  ëª©í‘œ      |

### 1.3 ë°±ì—… ëŒ€ìƒ

- **MySQL ë°ì´í„°ë² ì´ìŠ¤**: ì‚¬ìš©ì, ê²Œì‹œê¸€, ëŒ“ê¸€, ì•Œë¦¼
- **íŒŒì¼ ì‹œìŠ¤í…œ**: í”„ë¡œí•„ ì´ë¯¸ì§€, ì²¨ë¶€ íŒŒì¼
- **Redis ë°ì´í„°**: ìºì‹œ, ì„¸ì…˜
- **Elasticsearch ì¸ë±ìŠ¤**: ê²€ìƒ‰ ë°ì´í„°
- **ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ**: ì†ŒìŠ¤ ì½”ë“œ, ì„¤ì • íŒŒì¼
- **ë¡œê·¸ íŒŒì¼**: ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸, ì•¡ì„¸ìŠ¤ ë¡œê·¸

---

## 2. ë°±ì—… ì „ëµ

### 2.1 ë°±ì—… ìœ í˜•

#### ì „ì²´ ë°±ì—… (Full Backup)

**íŠ¹ì§•**:
- ëª¨ë“  ë°ì´í„° ì™„ì „ ë°±ì—…
- ë³µêµ¬ ì‹œê°„ ìµœì†Œí™”
- ìŠ¤í† ë¦¬ì§€ ê³µê°„ ë§ì´ ì‚¬ìš©

**ìŠ¤ì¼€ì¤„**: ë§¤ì¼ ìì • (00:00)

**êµ¬í˜„**:
```bash
#!/bin/bash
# full-backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/full"
DB_NAME="community_db"
DB_USER="backup_user"
DB_PASS="secure_password"

# MySQL ì „ì²´ ë°±ì—…
mysqldump --single-transaction \
    --routines \
    --triggers \
    --events \
    -u${DB_USER} \
    -p${DB_PASS} \
    ${DB_NAME} | gzip > ${BACKUP_DIR}/mysql_full_${DATE}.sql.gz

# íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…
tar -czf ${BACKUP_DIR}/files_full_${DATE}.tar.gz /var/www/uploads

# Redis ë°±ì—…
redis-cli BGSAVE
cp /var/lib/redis/dump.rdb ${BACKUP_DIR}/redis_full_${DATE}.rdb

# Elasticsearch ë°±ì—…
curl -X PUT "localhost:9200/_snapshot/my_backup/snapshot_${DATE}?wait_for_completion=true"

echo "Full backup completed: ${DATE}"
```

#### ì¦ë¶„ ë°±ì—… (Incremental Backup)

**íŠ¹ì§•**:
- ë§ˆì§€ë§‰ ë°±ì—… ì´í›„ ë³€ê²½ëœ ë°ì´í„°ë§Œ
- ìŠ¤í† ë¦¬ì§€ ê³µê°„ íš¨ìœ¨ì 
- ë³µêµ¬ ì‹œ ì—¬ëŸ¬ ë°±ì—… í•„ìš”

**ìŠ¤ì¼€ì¤„**: 6ì‹œê°„ë§ˆë‹¤ (06:00, 12:00, 18:00)

**êµ¬í˜„**:
```bash
#!/bin/bash
# incremental-backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/incremental"
LAST_BACKUP=$(ls -t /backups/full/*.sql.gz | head -1)

# MySQL ë°”ì´ë„ˆë¦¬ ë¡œê·¸ ë°±ì—…
mysqlbinlog --read-from-remote-server \
    --host=localhost \
    --user=${DB_USER} \
    --password=${DB_PASS} \
    --raw \
    --result-file=${BACKUP_DIR}/binlog_${DATE}

# ìµœê·¼ ë³€ê²½ íŒŒì¼ë§Œ ë°±ì—…
find /var/www/uploads -mmin -360 -type f \
    | tar -czf ${BACKUP_DIR}/files_incr_${DATE}.tar.gz -T -

echo "Incremental backup completed: ${DATE}"
```

#### ì°¨ë“± ë°±ì—… (Differential Backup)

**íŠ¹ì§•**:
- ë§ˆì§€ë§‰ ì „ì²´ ë°±ì—… ì´í›„ ëª¨ë“  ë³€ê²½ì‚¬í•­
- ì¦ë¶„ ë°±ì—…ë³´ë‹¤ ë³µêµ¬ ê°„ë‹¨
- ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ëŸ‰ ì¤‘ê°„

**ìŠ¤ì¼€ì¤„**: ë§¤ì¼ ì •ì˜¤ (12:00)

### 2.2 3-2-1 ë°±ì—… ê·œì¹™

```
3ê°œì˜ ë³µì‚¬ë³¸: ì›ë³¸ + ë°±ì—… 2ê°œ
2ê°€ì§€ ë§¤ì²´: ë¡œì»¬ ë””ìŠ¤í¬ + í´ë¼ìš°ë“œ
1ê°œì˜ ì˜¤í”„ì‚¬ì´íŠ¸: ë‹¤ë¥¸ ë¬¼ë¦¬ì  ìœ„ì¹˜
```

**êµ¬í˜„ ì˜ˆì‹œ**:
- **ë³µì‚¬ë³¸ 1**: ìš´ì˜ ì„œë²„ (ì›ë³¸)
- **ë³µì‚¬ë³¸ 2**: ë¡œì»¬ NAS (ë°±ì—… 1)
- **ë³µì‚¬ë³¸ 3**: AWS S3 (ë°±ì—… 2, ì˜¤í”„ì‚¬ì´íŠ¸)

---

## 3. ìë™ ë°±ì—… ì‹œìŠ¤í…œ

### 3.1 Cron ìŠ¤ì¼€ì¤„ ì„¤ì •

```bash
# /etc/crontab

# ì „ì²´ ë°±ì—… - ë§¤ì¼ ìì •
0 0 * * * root /opt/scripts/full-backup.sh >> /var/log/backup/full.log 2>&1

# ì¦ë¶„ ë°±ì—… - 6ì‹œê°„ë§ˆë‹¤
0 */6 * * * root /opt/scripts/incremental-backup.sh >> /var/log/backup/incremental.log 2>&1

# ë°±ì—… ê²€ì¦ - ë§¤ì¼ ìƒˆë²½ 2ì‹œ
0 2 * * * root /opt/scripts/verify-backup.sh >> /var/log/backup/verify.log 2>&1

# ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ - ë§¤ì¼ ìƒˆë²½ 3ì‹œ
0 3 * * * root /opt/scripts/cleanup-old-backups.sh >> /var/log/backup/cleanup.log 2>&1

# S3 ë™ê¸°í™” - ë§¤ì¼ ìƒˆë²½ 4ì‹œ
0 4 * * * root /opt/scripts/sync-to-s3.sh >> /var/log/backup/s3-sync.log 2>&1
```

### 3.2 MySQL ë°±ì—… ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# mysql-backup.sh

set -e

# ì„¤ì •
DB_HOST="localhost"
DB_PORT="3306"
DB_NAME="community_db"
DB_USER="backup_user"
DB_PASS="${MYSQL_BACKUP_PASSWORD}"
BACKUP_DIR="/backups/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p ${BACKUP_DIR}

# mysqldump ì‹¤í–‰
echo "[$(date)] Starting MySQL backup..."

mysqldump \
    --host=${DB_HOST} \
    --port=${DB_PORT} \
    --user=${DB_USER} \
    --password=${DB_PASS} \
    --single-transaction \
    --quick \
    --lock-tables=false \
    --routines \
    --triggers \
    --events \
    --databases ${DB_NAME} \
    | gzip -9 > ${BACKUP_DIR}/${DB_NAME}_${DATE}.sql.gz

# ë°±ì—… íŒŒì¼ í¬ê¸° í™•ì¸
BACKUP_FILE="${BACKUP_DIR}/${DB_NAME}_${DATE}.sql.gz"
FILE_SIZE=$(du -h ${BACKUP_FILE} | cut -f1)

echo "[$(date)] Backup completed: ${BACKUP_FILE} (${FILE_SIZE})"

# ì²´í¬ì„¬ ìƒì„±
md5sum ${BACKUP_FILE} > ${BACKUP_FILE}.md5

# ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find ${BACKUP_DIR} -name "*.sql.gz" -mtime +${RETENTION_DAYS} -delete
find ${BACKUP_DIR} -name "*.md5" -mtime +${RETENTION_DAYS} -delete

echo "[$(date)] Old backups cleaned up (older than ${RETENTION_DAYS} days)"

# ë°±ì—… ì„±ê³µ ì•Œë¦¼
curl -X POST https://api.slack.com/your-webhook \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"âœ… MySQL Backup Successful: ${FILE_SIZE}\"}"
```

### 3.3 íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…

```bash
#!/bin/bash
# filesystem-backup.sh

set -e

UPLOAD_DIR="/var/www/uploads"
BACKUP_DIR="/backups/files"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

echo "[$(date)] Starting filesystem backup..."

# tarë¥¼ ì‚¬ìš©í•œ ë°±ì—… (ì••ì¶•)
tar -czf ${BACKUP_DIR}/uploads_${DATE}.tar.gz \
    --exclude='*.tmp' \
    --exclude='cache/*' \
    ${UPLOAD_DIR}

# ë°±ì—… íŒŒì¼ í¬ê¸°
FILE_SIZE=$(du -h ${BACKUP_DIR}/uploads_${DATE}.tar.gz | cut -f1)

echo "[$(date)] Backup completed: ${FILE_SIZE}"

# ì²´í¬ì„¬ ìƒì„±
sha256sum ${BACKUP_DIR}/uploads_${DATE}.tar.gz > ${BACKUP_DIR}/uploads_${DATE}.tar.gz.sha256

# ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
find ${BACKUP_DIR} -name "uploads_*.tar.gz" -mtime +${RETENTION_DAYS} -delete

echo "[$(date)] Filesystem backup completed"
```

### 3.4 AWS S3 ë™ê¸°í™”

```bash
#!/bin/bash
# sync-to-s3.sh

set -e

BACKUP_DIR="/backups"
S3_BUCKET="s3://your-backup-bucket"
AWS_PROFILE="backup"

echo "[$(date)] Starting S3 sync..."

# AWS CLIë¥¼ ì‚¬ìš©í•œ ë™ê¸°í™”
aws s3 sync ${BACKUP_DIR} ${S3_BUCKET} \
    --profile ${AWS_PROFILE} \
    --storage-class GLACIER_IR \
    --exclude "*.log" \
    --exclude "tmp/*"

echo "[$(date)] S3 sync completed"

# ë™ê¸°í™” ìƒíƒœ í™•ì¸
SYNCED_FILES=$(aws s3 ls ${S3_BUCKET} --recursive --profile ${AWS_PROFILE} | wc -l)

echo "[$(date)] Total files in S3: ${SYNCED_FILES}"

# Slack ì•Œë¦¼
curl -X POST https://api.slack.com/your-webhook \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"â˜ï¸ S3 Sync Completed: ${SYNCED_FILES} files\"}"
```

### 3.5 Redis ë°±ì—…

```bash
#!/bin/bash
# redis-backup.sh

set -e

REDIS_HOST="localhost"
REDIS_PORT="6379"
BACKUP_DIR="/backups/redis"
DATE=$(date +%Y%m%d_%H%M%S)

echo "[$(date)] Starting Redis backup..."

# Redis BGSAVE íŠ¸ë¦¬ê±°
redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} BGSAVE

# BGSAVE ì™„ë£Œ ëŒ€ê¸°
while [ $(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} LASTSAVE) -eq $(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} LASTSAVE) ]; do
    sleep 1
done

# dump.rdb ë³µì‚¬
cp /var/lib/redis/dump.rdb ${BACKUP_DIR}/dump_${DATE}.rdb

# ì••ì¶•
gzip ${BACKUP_DIR}/dump_${DATE}.rdb

echo "[$(date)] Redis backup completed"
```

### 3.6 Elasticsearch ìŠ¤ëƒ…ìƒ·

```bash
#!/bin/bash
# elasticsearch-backup.sh

set -e

ES_HOST="localhost:9200"
SNAPSHOT_REPO="backup_repository"
DATE=$(date +%Y%m%d_%H%M%S)
SNAPSHOT_NAME="snapshot_${DATE}"

echo "[$(date)] Starting Elasticsearch snapshot..."

# ìŠ¤ëƒ…ìƒ· ìƒì„±
curl -X PUT "${ES_HOST}/_snapshot/${SNAPSHOT_REPO}/${SNAPSHOT_NAME}?wait_for_completion=true" \
    -H 'Content-Type: application/json' \
    -d'{
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }'

echo "[$(date)] Elasticsearch snapshot completed: ${SNAPSHOT_NAME}"

# ì˜¤ë˜ëœ ìŠ¤ëƒ…ìƒ· ì‚­ì œ (30ì¼ ì´ìƒ)
SNAPSHOTS=$(curl -s "${ES_HOST}/_snapshot/${SNAPSHOT_REPO}/_all" | jq -r '.snapshots[].snapshot')

for snapshot in ${SNAPSHOTS}; do
    SNAPSHOT_DATE=$(echo $snapshot | grep -oP '\d{8}')
    DAYS_OLD=$(( ($(date +%s) - $(date -d $SNAPSHOT_DATE +%s)) / 86400 ))
    
    if [ $DAYS_OLD -gt 30 ]; then
        curl -X DELETE "${ES_HOST}/_snapshot/${SNAPSHOT_REPO}/${snapshot}"
        echo "[$(date)] Deleted old snapshot: ${snapshot}"
    fi
done
```

---

## 4. ë°ì´í„° ë³µêµ¬ ì ˆì°¨

### 4.1 MySQL ë³µêµ¬

#### ì „ì²´ ë³µêµ¬

```bash
#!/bin/bash
# mysql-restore.sh

set -e

BACKUP_FILE="/backups/mysql/community_db_20251112_000000.sql.gz"
DB_NAME="community_db"
DB_USER="root"
DB_PASS="${MYSQL_ROOT_PASSWORD}"

echo "[$(date)] Starting MySQL restore from ${BACKUP_FILE}"

# ë°±ì—… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
echo "Verifying backup integrity..."
md5sum -c ${BACKUP_FILE}.md5

# ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ì•ˆì „ì¥ì¹˜)
echo "Creating safety backup of current database..."
mysqldump -u${DB_USER} -p${DB_PASS} ${DB_NAME} | gzip > /tmp/pre_restore_${DB_NAME}_$(date +%Y%m%d_%H%M%S).sql.gz

# ë³µêµ¬ ì‹¤í–‰
echo "Restoring database..."
gunzip < ${BACKUP_FILE} | mysql -u${DB_USER} -p${DB_PASS} ${DB_NAME}

echo "[$(date)] MySQL restore completed successfully"

# ë°ì´í„° ê²€ì¦
TABLES_COUNT=$(mysql -u${DB_USER} -p${DB_PASS} -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='${DB_NAME}'" -s -N)
echo "Tables count after restore: ${TABLES_COUNT}"
```

#### Point-in-Time ë³µêµ¬

```bash
#!/bin/bash
# mysql-pitr.sh

set -e

FULL_BACKUP="/backups/mysql/community_db_20251112_000000.sql.gz"
BINLOG_DIR="/backups/incremental"
TARGET_TIME="2025-11-12 14:30:00"

echo "Starting Point-in-Time Recovery to ${TARGET_TIME}"

# 1. ì „ì²´ ë°±ì—… ë³µêµ¬
echo "Step 1: Restoring full backup..."
gunzip < ${FULL_BACKUP} | mysql -uroot -p${MYSQL_ROOT_PASSWORD} community_db

# 2. ë°”ì´ë„ˆë¦¬ ë¡œê·¸ ì ìš©
echo "Step 2: Applying binary logs..."
mysqlbinlog --stop-datetime="${TARGET_TIME}" \
    ${BINLOG_DIR}/mysql-bin.* | mysql -uroot -p${MYSQL_ROOT_PASSWORD}

echo "Point-in-Time Recovery completed"
```

### 4.2 íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬

```bash
#!/bin/bash
# filesystem-restore.sh

set -e

BACKUP_FILE="/backups/files/uploads_20251112_000000.tar.gz"
RESTORE_DIR="/var/www/uploads"

echo "[$(date)] Starting filesystem restore"

# ì²´í¬ì„¬ ê²€ì¦
sha256sum -c ${BACKUP_FILE}.sha256

# ê¸°ì¡´ íŒŒì¼ ë°±ì—…
mv ${RESTORE_DIR} ${RESTORE_DIR}.bak_$(date +%Y%m%d_%H%M%S)

# ë³µêµ¬ ì‹¤í–‰
mkdir -p ${RESTORE_DIR}
tar -xzf ${BACKUP_FILE} -C /var/www/

# ê¶Œí•œ ë³µì›
chown -R www-data:www-data ${RESTORE_DIR}
chmod -R 755 ${RESTORE_DIR}

echo "[$(date)] Filesystem restore completed"
```

### 4.3 Redis ë³µêµ¬

```bash
#!/bin/bash
# redis-restore.sh

set -e

BACKUP_FILE="/backups/redis/dump_20251112_000000.rdb.gz"
REDIS_DATA_DIR="/var/lib/redis"

echo "[$(date)] Starting Redis restore"

# Redis ì¤‘ì§€
systemctl stop redis-server

# ê¸°ì¡´ dump.rdb ë°±ì—…
if [ -f ${REDIS_DATA_DIR}/dump.rdb ]; then
    mv ${REDIS_DATA_DIR}/dump.rdb ${REDIS_DATA_DIR}/dump.rdb.bak_$(date +%Y%m%d_%H%M%S)
fi

# ë³µêµ¬ ì‹¤í–‰
gunzip -c ${BACKUP_FILE} > ${REDIS_DATA_DIR}/dump.rdb

# ê¶Œí•œ ë³µì›
chown redis:redis ${REDIS_DATA_DIR}/dump.rdb

# Redis ì¬ì‹œì‘
systemctl start redis-server

# ë³µêµ¬ í™•ì¸
redis-cli ping

echo "[$(date)] Redis restore completed"
```

### 4.4 Elasticsearch ë³µêµ¬

```bash
#!/bin/bash
# elasticsearch-restore.sh

set -e

ES_HOST="localhost:9200"
SNAPSHOT_REPO="backup_repository"
SNAPSHOT_NAME="snapshot_20251112_000000"

echo "[$(date)] Starting Elasticsearch restore from ${SNAPSHOT_NAME}"

# ëª¨ë“  ì¸ë±ìŠ¤ ë‹«ê¸°
curl -X POST "${ES_HOST}/_all/_close"

# ìŠ¤ëƒ…ìƒ· ë³µêµ¬
curl -X POST "${ES_HOST}/_snapshot/${SNAPSHOT_REPO}/${SNAPSHOT_NAME}/_restore" \
    -H 'Content-Type: application/json' \
    -d'{
        "indices": "*",
        "ignore_unavailable": true,
        "include_global_state": false
    }'

# ë³µêµ¬ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
while true; do
    STATUS=$(curl -s "${ES_HOST}/_snapshot/${SNAPSHOT_REPO}/${SNAPSHOT_NAME}/_status" | jq -r '.snapshots[0].state')
    if [ "$STATUS" == "SUCCESS" ]; then
        break
    fi
    echo "Restore in progress... Status: ${STATUS}"
    sleep 10
done

# ëª¨ë“  ì¸ë±ìŠ¤ ì—´ê¸°
curl -X POST "${ES_HOST}/_all/_open"

echo "[$(date)] Elasticsearch restore completed"
```

---

## 5. ì¬í•´ ë³µêµ¬ ê³„íš (DRP)

### 5.1 ì¬í•´ ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: ë°ì´í„°ë² ì´ìŠ¤ ì†ìƒ

**ì˜í–¥**: ëª¨ë“  ì‚¬ìš©ì ë°ì´í„° ì ‘ê·¼ ë¶ˆê°€

**ë³µêµ¬ ì ˆì°¨**:
1. **ì¦‰ì‹œ ì¡°ì¹˜** (0-15ë¶„)
   - ì„œë¹„ìŠ¤ ì ê²€ ëª¨ë“œ ì „í™˜
   - ë¬¸ì œ ì›ì¸ íŒŒì•…
   - ë°±ì—… íŒ€ ì†Œì§‘

2. **ë³µêµ¬ ì‹¤í–‰** (15-60ë¶„)
   - ìµœì‹  ì „ì²´ ë°±ì—… í™•ì¸
   - PITR(Point-in-Time Recovery) ì¤€ë¹„
   - ë³µêµ¬ ì‹¤í–‰

3. **ê²€ì¦** (60-90ë¶„)
   - ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
   - ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
   - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

4. **ì„œë¹„ìŠ¤ ì¬ê°œ** (90-120ë¶„)
   - ì ê²€ ëª¨ë“œ í•´ì œ
   - ì‚¬ìš©ì ê³µì§€
   - ëª¨ë‹ˆí„°ë§ ê°•í™”

**ëª©í‘œ RTO**: 2ì‹œê°„

#### ì‹œë‚˜ë¦¬ì˜¤ 2: ì „ì²´ ì„œë²„ ì¥ì• 

**ì˜í–¥**: ì „ì²´ ì„œë¹„ìŠ¤ ë‹¤ìš´

**ë³µêµ¬ ì ˆì°¨**:
1. **ì¦‰ì‹œ ì¡°ì¹˜** (0-30ë¶„)
   - DR ì‚¬ì´íŠ¸ í™œì„±í™”
   - DNS ì „í™˜ ì¤€ë¹„

2. **DR ì‚¬ì´íŠ¸ êµ¬ë™** (30-120ë¶„)
   - ë°±ì—… ì„œë²„ ë¶€íŒ…
   - ìµœì‹  ë°±ì—… ë³µêµ¬
   - ë¡œë“œ ë°¸ëŸ°ì„œ ì„¤ì •

3. **ì„œë¹„ìŠ¤ ì „í™˜** (120-180ë¶„)
   - DNS ë ˆì½”ë“œ ë³€ê²½
   - SSL ì¸ì¦ì„œ í™•ì¸
   - ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸

**ëª©í‘œ RTO**: 3ì‹œê°„

#### ì‹œë‚˜ë¦¬ì˜¤ 3: ëœì„¬ì›¨ì–´ ê³µê²©

**ì˜í–¥**: ë°ì´í„° ì•”í˜¸í™”

**ë³µêµ¬ ì ˆì°¨**:
1. **ê²©ë¦¬** (0-15ë¶„)
   - ê°ì—¼ ì„œë²„ ë„¤íŠ¸ì›Œí¬ ì°¨ë‹¨
   - í™•ì‚° ë°©ì§€

2. **í‰ê°€** (15-60ë¶„)
   - í”¼í•´ ë²”ìœ„ íŒŒì•…
   - í´ë¦° ë°±ì—… ì‹ë³„

3. **ë³µêµ¬** (60-240ë¶„)
   - ê°ì—¼ ì´ì „ ë°±ì—… ë³µêµ¬
   - ì‹œìŠ¤í…œ ì¬êµ¬ì¶•
   - ë³´ì•ˆ íŒ¨ì¹˜ ì ìš©

**ëª©í‘œ RTO**: 4ì‹œê°„

### 5.2 DR ì‚¬ì´íŠ¸ êµ¬ì„±

```yaml
# docker-compose-dr.yml
version: '3.8'

services:
  mysql-dr:
    image: mysql:8.0
    environment:
      MYSQL_ROOT_PASSWORD: ${DR_MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: community_db
    volumes:
      - /dr/mysql-data:/var/lib/mysql
      - /dr/mysql-backup:/backups
    command: --default-authentication-plugin=mysql_native_password
    networks:
      - dr-network

  redis-dr:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - /dr/redis-data:/data
    networks:
      - dr-network

  elasticsearch-dr:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - /dr/elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - dr-network

  app-dr:
    image: community-platform:latest
    environment:
      NODE_ENV: production
      DB_HOST: mysql-dr
      REDIS_HOST: redis-dr
      ELASTICSEARCH_HOST: elasticsearch-dr
    depends_on:
      - mysql-dr
      - redis-dr
      - elasticsearch-dr
    networks:
      - dr-network

networks:
  dr-network:
    driver: bridge
```

### 5.3 ë³µêµ¬ ìš°ì„ ìˆœìœ„

| ìš°ì„ ìˆœìœ„      | ì„œë¹„ìŠ¤               | ëª©í‘œ RTO | ë³µêµ¬ ìˆœì„œ |
| ------------- | -------------------- | -------- | --------- |
| **P0 (ê¸´ê¸‰)** | ë°ì´í„°ë² ì´ìŠ¤         | 1ì‹œê°„    | 1ìˆœìœ„     |
| **P1 (ì¤‘ìš”)** | ì¸ì¦ ì‹œìŠ¤í…œ          | 2ì‹œê°„    | 2ìˆœìœ„     |
| **P1 (ì¤‘ìš”)** | ì½”ì–´ API             | 2ì‹œê°„    | 3ìˆœìœ„     |
| **P2 (ì¼ë°˜)** | ê²€ìƒ‰ (Elasticsearch) | 4ì‹œê°„    | 4ìˆœìœ„     |
| **P2 (ì¼ë°˜)** | ì±„íŒ…                 | 4ì‹œê°„    | 5ìˆœìœ„     |
| **P3 (ë‚®ìŒ)** | ì•Œë¦¼ ì‹œìŠ¤í…œ          | 8ì‹œê°„    | 6ìˆœìœ„     |

---

## 6. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦

### 6.1 ë°±ì—… ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# verify-backup.sh

set -e

BACKUP_DIR="/backups/mysql"
LATEST_BACKUP=$(ls -t ${BACKUP_DIR}/*.sql.gz | head -1)
TEST_DB="backup_test_db"
DB_USER="root"
DB_PASS="${MYSQL_ROOT_PASSWORD}"

echo "[$(date)] Starting backup verification: ${LATEST_BACKUP}"

# 1. íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦
echo "Step 1: Verifying file integrity..."
if md5sum -c ${LATEST_BACKUP}.md5; then
    echo "âœ… Checksum verified"
else
    echo "âŒ Checksum verification failed"
    exit 1
fi

# 2. ì••ì¶• íŒŒì¼ ê²€ì¦
echo "Step 2: Verifying gzip integrity..."
if gunzip -t ${LATEST_BACKUP}; then
    echo "âœ… Gzip integrity verified"
else
    echo "âŒ Gzip integrity check failed"
    exit 1
fi

# 3. SQL ë³µêµ¬ í…ŒìŠ¤íŠ¸
echo "Step 3: Testing database restore..."

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
mysql -u${DB_USER} -p${DB_PASS} -e "DROP DATABASE IF EXISTS ${TEST_DB}"
mysql -u${DB_USER} -p${DB_PASS} -e "CREATE DATABASE ${TEST_DB}"

# ë°±ì—… ë³µêµ¬ ì‹œë„
if gunzip < ${LATEST_BACKUP} | mysql -u${DB_USER} -p${DB_PASS} ${TEST_DB}; then
    echo "âœ… Database restore successful"
else
    echo "âŒ Database restore failed"
    mysql -u${DB_USER} -p${DB_PASS} -e "DROP DATABASE IF EXISTS ${TEST_DB}"
    exit 1
fi

# 4. ë°ì´í„° ê²€ì¦
echo "Step 4: Verifying data..."

# í…Œì´ë¸” ìˆ˜ í™•ì¸
TABLES_COUNT=$(mysql -u${DB_USER} -p${DB_PASS} -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='${TEST_DB}'" -s -N)
echo "Tables count: ${TABLES_COUNT}"

# ì‚¬ìš©ì ìˆ˜ í™•ì¸
USERS_COUNT=$(mysql -u${DB_USER} -p${DB_PASS} ${TEST_DB} -e "SELECT COUNT(*) FROM users" -s -N)
echo "Users count: ${USERS_COUNT}"

# ê²Œì‹œê¸€ ìˆ˜ í™•ì¸
POSTS_COUNT=$(mysql -u${DB_USER} -p${DB_PASS} ${TEST_DB} -e "SELECT COUNT(*) FROM posts" -s -N)
echo "Posts count: ${POSTS_COUNT}"

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ
mysql -u${DB_USER} -p${DB_PASS} -e "DROP DATABASE ${TEST_DB}"

echo "[$(date)] âœ… Backup verification completed successfully"

# Slack ì•Œë¦¼
curl -X POST https://api.slack.com/your-webhook \
    -H 'Content-Type: application/json' \
    -d "{\"text\":\"âœ… Backup Verification Passed: ${LATEST_BACKUP}\n- Tables: ${TABLES_COUNT}\n- Users: ${USERS_COUNT}\n- Posts: ${POSTS_COUNT}\"}"
```

### 6.2 ë°ì´í„° ì¼ê´€ì„± ì²´í¬

```bash
#!/bin/bash
# check-data-consistency.sh

DB_NAME="community_db"
DB_USER="root"
DB_PASS="${MYSQL_ROOT_PASSWORD}"

echo "[$(date)] Starting data consistency check"

# ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´ í™•ì¸
echo "Checking foreign key constraints..."
mysql -u${DB_USER} -p${DB_PASS} ${DB_NAME} -e "
    SELECT 
        TABLE_NAME, 
        CONSTRAINT_NAME, 
        CONSTRAINT_TYPE 
    FROM information_schema.TABLE_CONSTRAINTS 
    WHERE CONSTRAINT_SCHEMA = '${DB_NAME}' 
    AND CONSTRAINT_TYPE = 'FOREIGN KEY'
"

# ê³ ì•„ ë ˆì½”ë“œ ì°¾ê¸°
echo "Checking for orphaned records..."

# ê²Œì‹œê¸€ ì—†ëŠ” ëŒ“ê¸€
ORPHANED_COMMENTS=$(mysql -u${DB_USER} -p${DB_PASS} ${DB_NAME} -s -N -e "
    SELECT COUNT(*) 
    FROM comments c 
    LEFT JOIN posts p ON c.post_id = p.id 
    WHERE p.id IS NULL
")
echo "Orphaned comments: ${ORPHANED_COMMENTS}"

# ì‚¬ìš©ì ì—†ëŠ” ê²Œì‹œê¸€
ORPHANED_POSTS=$(mysql -u${DB_USER} -p${DB_PASS} ${DB_NAME} -s -N -e "
    SELECT COUNT(*) 
    FROM posts p 
    LEFT JOIN users u ON p.author_id = u.id 
    WHERE u.id IS NULL
")
echo "Orphaned posts: ${ORPHANED_POSTS}"

# ì¤‘ë³µ ë°ì´í„° í™•ì¸
echo "Checking for duplicate data..."
DUPLICATE_USERS=$(mysql -u${DB_USER} -p${DB_PASS} ${DB_NAME} -s -N -e "
    SELECT email, COUNT(*) 
    FROM users 
    GROUP BY email 
    HAVING COUNT(*) > 1
")

if [ -z "$DUPLICATE_USERS" ]; then
    echo "âœ… No duplicate users found"
else
    echo "âš ï¸ Duplicate users detected:"
    echo "$DUPLICATE_USERS"
fi

echo "[$(date)] Data consistency check completed"
```

---

## 7. ë°±ì—… ëª¨ë‹ˆí„°ë§

### 7.1 ë°±ì—… ìƒíƒœ ëª¨ë‹ˆí„°ë§

```javascript
// server-backend/services/backupMonitorService.js

const fs = require('fs');
const path = require('path');
const { promisify } = require('util');
const stat = promisify(fs.stat);

class BackupMonitorService {
    constructor() {
        this.backupDir = '/backups';
        this.maxBackupAge = 24 * 60 * 60 * 1000; // 24 hours
    }

    async checkLatestBackup() {
        try {
            const mysqlBackupDir = path.join(this.backupDir, 'mysql');
            const files = await fs.promises.readdir(mysqlBackupDir);
            
            // ìµœì‹  ë°±ì—… íŒŒì¼ ì°¾ê¸°
            const backupFiles = files
                .filter(f => f.endsWith('.sql.gz'))
                .map(f => path.join(mysqlBackupDir, f));

            if (backupFiles.length === 0) {
                return {
                    status: 'error',
                    message: 'No backup files found'
                };
            }

            // ìµœì‹  íŒŒì¼ í†µê³„
            const latestFile = backupFiles[backupFiles.length - 1];
            const stats = await stat(latestFile);
            const ageMs = Date.now() - stats.mtime.getTime();

            if (ageMs > this.maxBackupAge) {
                return {
                    status: 'warning',
                    message: `Latest backup is ${Math.floor(ageMs / (60 * 60 * 1000))} hours old`,
                    file: latestFile,
                    age: ageMs
                };
            }

            return {
                status: 'success',
                message: 'Backup is up to date',
                file: latestFile,
                size: stats.size,
                age: ageMs
            };
        } catch (error) {
            return {
                status: 'error',
                message: error.message
            };
        }
    }

    async getBackupMetrics() {
        const metrics = {
            mysql: await this.getDirectoryMetrics(path.join(this.backupDir, 'mysql')),
            files: await this.getDirectoryMetrics(path.join(this.backupDir, 'files')),
            redis: await this.getDirectoryMetrics(path.join(this.backupDir, 'redis'))
        };

        return metrics;
    }

    async getDirectoryMetrics(dir) {
        try {
            const files = await fs.promises.readdir(dir);
            let totalSize = 0;
            let fileCount = 0;

            for (const file of files) {
                const filePath = path.join(dir, file);
                const stats = await stat(filePath);
                if (stats.isFile()) {
                    totalSize += stats.size;
                    fileCount++;
                }
            }

            return {
                fileCount,
                totalSize,
                totalSizeGB: (totalSize / (1024 ** 3)).toFixed(2)
            };
        } catch (error) {
            return {
                fileCount: 0,
                totalSize: 0,
                error: error.message
            };
        }
    }
}

module.exports = new BackupMonitorService();
```

### 7.2 ë°±ì—… ì•Œë¦¼ ì„¤ì •

```javascript
// server-backend/services/backupAlertService.js

const axios = require('axios');

class BackupAlertService {
    constructor() {
        this.slackWebhook = process.env.SLACK_BACKUP_WEBHOOK;
        this.emailRecipients = process.env.BACKUP_ALERT_EMAILS?.split(',') || [];
    }

    async sendBackupSuccessAlert(backupInfo) {
        const message = {
            text: 'âœ… Backup Successful',
            blocks: [
                {
                    type: 'header',
                    text: {
                        type: 'plain_text',
                        text: 'âœ… Backup Completed Successfully'
                    }
                },
                {
                    type: 'section',
                    fields: [
                        {
                            type: 'mrkdwn',
                            text: `*Type:*\n${backupInfo.type}`
                        },
                        {
                            type: 'mrkdwn',
                            text: `*Size:*\n${backupInfo.size}`
                        },
                        {
                            type: 'mrkdwn',
                            text: `*Duration:*\n${backupInfo.duration}s`
                        },
                        {
                            type: 'mrkdwn',
                            text: `*Time:*\n${new Date().toISOString()}`
                        }
                    ]
                }
            ]
        };

        await this.sendSlackMessage(message);
    }

    async sendBackupFailureAlert(error) {
        const message = {
            text: 'âŒ Backup Failed',
            blocks: [
                {
                    type: 'header',
                    text: {
                        type: 'plain_text',
                        text: 'âŒ Backup Failed'
                    }
                },
                {
                    type: 'section',
                    text: {
                        type: 'mrkdwn',
                        text: `*Error:*\n\`\`\`${error.message}\`\`\``
                    }
                },
                {
                    type: 'section',
                    fields: [
                        {
                            type: 'mrkdwn',
                            text: `*Time:*\n${new Date().toISOString()}`
                        },
                        {
                            type: 'mrkdwn',
                            text: `*Severity:*\nCritical`
                        }
                    ]
                }
            ]
        };

        await this.sendSlackMessage(message);
    }

    async sendOldBackupWarning(ageHours) {
        const message = {
            text: 'âš ï¸ Old Backup Warning',
            blocks: [
                {
                    type: 'header',
                    text: {
                        type: 'plain_text',
                        text: 'âš ï¸ Backup is Outdated'
                    }
                },
                {
                    type: 'section',
                    text: {
                        type: 'mrkdwn',
                        text: `Latest backup is *${ageHours} hours* old. Expected: < 24 hours`
                    }
                }
            ]
        };

        await this.sendSlackMessage(message);
    }

    async sendSlackMessage(message) {
        if (!this.slackWebhook) {
            console.log('Slack webhook not configured');
            return;
        }

        try {
            await axios.post(this.slackWebhook, message);
        } catch (error) {
            console.error('Failed to send Slack notification:', error.message);
        }
    }
}

module.exports = new BackupAlertService();
```

---

## 8. ë³µêµ¬ í…ŒìŠ¤íŠ¸

### 8.1 ì •ê¸° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ê³„íš

| ë¹ˆë„     | í…ŒìŠ¤íŠ¸ ìœ í˜•            | ë²”ìœ„               |
| -------- | ---------------------- | ------------------ |
| **ì£¼ê°„** | ë‹¨ì¼ í…Œì´ë¸” ë³µêµ¬       | ë¬´ì‘ìœ„ í…Œì´ë¸” ì„ íƒ |
| **ì›”ê°„** | ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ | ëª¨ë“  ë°ì´í„°        |
| **ë¶„ê¸°** | DR ì‚¬ì´íŠ¸ ì „í™˜         | ì „ì²´ ì‹œìŠ¤í…œ        |
| **ì—°ê°„** | ì¬í•´ ë³µêµ¬ í›ˆë ¨         | ì „ì‚¬ì  í›ˆë ¨        |

### 8.2 ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ì „ ì¤€ë¹„
- [ ] í…ŒìŠ¤íŠ¸ í™˜ê²½ ì¤€ë¹„ ì™„ë£Œ
- [ ] ë°±ì—… íŒŒì¼ í™•ì¸ (ìµœì‹ , ë¬´ê²°ì„±)
- [ ] í…ŒìŠ¤íŠ¸ íŒ€ ì†Œì§‘
- [ ] íƒ€ì„ë¼ì¸ ì„¤ì •

### ë³µêµ¬ ì‹¤í–‰
- [ ] ë°±ì—… íŒŒì¼ ë³µì‚¬
- [ ] ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
- [ ] ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- [ ] ì—ëŸ¬ ë¡œê·¸ í™•ì¸

### ê²€ì¦
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
- [ ] í…Œì´ë¸” ìˆ˜ í™•ì¸
- [ ] ë ˆì½”ë“œ ìˆ˜ í™•ì¸
- [ ] ì™¸ë˜ í‚¤ ë¬´ê²°ì„± í™•ì¸
- [ ] ìƒ˜í”Œ ì¿¼ë¦¬ ì‹¤í–‰
- [ ] ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

### ë¬¸ì„œí™”
- [ ] ë³µêµ¬ ì‹œê°„ ê¸°ë¡ (RTO)
- [ ] ë°ì´í„° ì†ì‹¤ í™•ì¸ (RPO)
- [ ] ë¬¸ì œì  ê¸°ë¡
- [ ] ê°œì„  ì‚¬í•­ ë„ì¶œ

### ì •ë¦¬
- [ ] í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
- [ ] ë³´ê³ ì„œ ì‘ì„±
- [ ] íŒ€ í”¼ë“œë°±
```

### 8.3 ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ í…œí”Œë¦¿

```markdown
# ë°±ì—… ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ

**í…ŒìŠ¤íŠ¸ ë‚ ì§œ**: 2025-11-12  
**í…ŒìŠ¤íŠ¸ ë‹´ë‹¹ì**: [ì´ë¦„]  
**í…ŒìŠ¤íŠ¸ ìœ í˜•**: ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬

## 1. í…ŒìŠ¤íŠ¸ ê°œìš”

- **ë°±ì—… íŒŒì¼**: community_db_20251112_000000.sql.gz
- **ë°±ì—… ë‚ ì§œ**: 2025-11-12 00:00:00
- **ë°±ì—… í¬ê¸°**: 2.3 GB
- **í…ŒìŠ¤íŠ¸ í™˜ê²½**: ìŠ¤í…Œì´ì§• ì„œë²„

## 2. í…ŒìŠ¤íŠ¸ ê²°ê³¼

### 2.1 ë³µêµ¬ ì‹œê°„

| ë‹¨ê³„              | ì†Œìš” ì‹œê°„ | ëˆ„ì  ì‹œê°„ |
| ----------------- | --------- | --------- |
| ë°±ì—… íŒŒì¼ ë³µì‚¬    | 5ë¶„       | 5ë¶„       |
| ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ | 25ë¶„      | 30ë¶„      |
| ì¸ë±ìŠ¤ ì¬êµ¬ì¶•     | 10ë¶„      | 40ë¶„      |
| ê²€ì¦              | 5ë¶„       | 45ë¶„      |
| **ì´ ì‹œê°„**       | -         | **45ë¶„**  |

**RTO ëª©í‘œ**: 2ì‹œê°„ âœ… **ë‹¬ì„±**

### 2.2 ë°ì´í„° ë¬´ê²°ì„±

| í•­ëª©      | ì˜ˆìƒ   | ì‹¤ì œ   | ìƒíƒœ |
| --------- | ------ | ------ | ---- |
| í…Œì´ë¸” ìˆ˜ | 25     | 25     | âœ…    |
| ì‚¬ìš©ì ìˆ˜ | 1,523  | 1,523  | âœ…    |
| ê²Œì‹œê¸€ ìˆ˜ | 8,742  | 8,742  | âœ…    |
| ëŒ“ê¸€ ìˆ˜   | 23,456 | 23,456 | âœ…    |
| íŒŒì¼ ìˆ˜   | 3,421  | 3,421  | âœ…    |

### 2.3 ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸

- âœ… ë¡œê·¸ì¸
- âœ… ê²Œì‹œê¸€ ì‘ì„±
- âœ… ëŒ“ê¸€ ì‘ì„±
- âœ… ê²€ìƒ‰
- âœ… íŒŒì¼ ì—…ë¡œë“œ

## 3. ë¬¸ì œì  ë° ê°œì„ ì‚¬í•­

### ë¬¸ì œì 
1. ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹œê°„ì´ ì˜ˆìƒë³´ë‹¤ 5ë¶„ ê¸¸ì—ˆìŒ
2. í…ŒìŠ¤íŠ¸ í™˜ê²½ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ê²½ê³ 

### ê°œì„ ì‚¬í•­
1. ì¸ë±ìŠ¤ ìµœì í™” ê²€í†  í•„ìš”
2. í…ŒìŠ¤íŠ¸ í™˜ê²½ ë””ìŠ¤í¬ ìš©ëŸ‰ ì¦ì„¤ ê³„íš

## 4. ê²°ë¡ 

ì „ì²´ ë³µêµ¬ í…ŒìŠ¤íŠ¸ **ì„±ê³µ**. RTO ëª©í‘œ ì‹œê°„ ë‚´ ë³µêµ¬ ì™„ë£Œ.
ì •ê¸°ì ì¸ í…ŒìŠ¤íŠ¸ë¡œ ë³µêµ¬ ì ˆì°¨ ìˆ™ë ¨ë„ í–¥ìƒ í•„ìš”.

---

**ê²€í† ì**: [ì´ë¦„]  
**ìŠ¹ì¸**: [ì´ë¦„]
```

---

## 9. ì²´í¬ë¦¬ìŠ¤íŠ¸

### 9.1 ë°±ì—… ì‹œìŠ¤í…œ

- [ ] MySQL ìë™ ë°±ì—… ì„¤ì • ì™„ë£Œ
- [ ] íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—… ì„¤ì • ì™„ë£Œ
- [ ] Redis ë°±ì—… ì„¤ì • ì™„ë£Œ
- [ ] Elasticsearch ìŠ¤ëƒ…ìƒ· ì„¤ì • ì™„ë£Œ
- [ ] Cron ìŠ¤ì¼€ì¤„ ë“±ë¡ ì™„ë£Œ
- [ ] ë°±ì—… ë¡œê·¸ í™•ì¸ ê°€ëŠ¥
- [ ] ë°±ì—… ì•Œë¦¼ ì„¤ì • ì™„ë£Œ

### 9.2 ë³µêµ¬ ì‹œìŠ¤í…œ

- [ ] ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™” ì™„ë£Œ
- [ ] PITR ì„¤ì • ì™„ë£Œ
- [ ] DR ì‚¬ì´íŠ¸ êµ¬ì¶• ì™„ë£Œ
- [ ] DNS ì „í™˜ ê³„íš ìˆ˜ë¦½
- [ ] ë³µêµ¬ ìš°ì„ ìˆœìœ„ ì •ì˜ ì™„ë£Œ

### 9.3 ê²€ì¦ ë° í…ŒìŠ¤íŠ¸

- [ ] ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ìë™í™”
- [ ] ë°ì´í„° ì¼ê´€ì„± ì²´í¬ ìŠ¤í¬ë¦½íŠ¸
- [ ] ì£¼ê°„ ë³µêµ¬ í…ŒìŠ¤íŠ¸ ìŠ¤ì¼€ì¤„
- [ ] ì›”ê°„ DR í…ŒìŠ¤íŠ¸ ê³„íš
- [ ] ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ í…œí”Œë¦¿

### 9.4 ëª¨ë‹ˆí„°ë§

- [ ] ë°±ì—… ìƒíƒœ ëŒ€ì‹œë³´ë“œ
- [ ] ë°±ì—… ì‹¤íŒ¨ ì•Œë¦¼
- [ ] ì˜¤ë˜ëœ ë°±ì—… ê²½ê³ 
- [ ] ìŠ¤í† ë¦¬ì§€ ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
- [ ] ë°±ì—… ì„±ëŠ¥ ë©”íŠ¸ë¦­

---

## 10. êµ¬í˜„ ë¡œë“œë§µ

### Week 1: ê¸°ë³¸ ë°±ì—… ì‹œìŠ¤í…œ

**ëª©í‘œ**: í•µì‹¬ ë°ì´í„° ë°±ì—… ìë™í™”

- **Day 1-2**: MySQL ë°±ì—…
  - [ ] mysqldump ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
  - [ ] ì „ì²´ ë°±ì—… Cron ì„¤ì •
  - [ ] ë°±ì—… ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ê³„

- **Day 3**: íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…
  - [ ] tar ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
  - [ ] ì¦ë¶„ ë°±ì—… ë¡œì§ êµ¬í˜„
  - [ ] ë°±ì—… ì••ì¶• ìµœì í™”

- **Day 4**: Redis & Elasticsearch
  - [ ] Redis BGSAVE ìë™í™”
  - [ ] Elasticsearch ìŠ¤ëƒ…ìƒ· ì„¤ì •
  - [ ] ìŠ¤ëƒ…ìƒ· ë¦¬í¬ì§€í† ë¦¬ êµ¬ì„±

- **Day 5**: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
  - [ ] ëª¨ë“  ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ í…ŒìŠ¤íŠ¸
  - [ ] ë¡œê·¸ í™•ì¸
  - [ ] ë¬¸ì œ ìˆ˜ì •

### Week 2: ê³ ê¸‰ ë°±ì—… ê¸°ëŠ¥

**ëª©í‘œ**: ì¦ë¶„ ë°±ì—… ë° ì›ê²© ë°±ì—…

- **Day 1-2**: ì¦ë¶„ ë°±ì—…
  - [ ] MySQL ë°”ì´ë„ˆë¦¬ ë¡œê·¸ ë°±ì—…
  - [ ] íŒŒì¼ ì‹œìŠ¤í…œ ì¦ë¶„ ë°±ì—…
  - [ ] ë°±ì—… ì²´ì¸ ê´€ë¦¬

- **Day 3-4**: AWS S3 ë™ê¸°í™”
  - [ ] AWS CLI ì„¤ì •
  - [ ] S3 ë²„í‚· ìƒì„±
  - [ ] ë™ê¸°í™” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
  - [ ] Glacier ì •ì±… ì„¤ì •

- **Day 5**: ë°±ì—… ì •ë¦¬
  - [ ] ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ ìŠ¤í¬ë¦½íŠ¸
  - [ ] ë³´ê´€ ì •ì±… êµ¬í˜„
  - [ ] ìŠ¤í† ë¦¬ì§€ ìµœì í™”

### Week 3: ë³µêµ¬ ì‹œìŠ¤í…œ

**ëª©í‘œ**: ë³µêµ¬ ì ˆì°¨ í™•ë¦½ ë° DR ì‚¬ì´íŠ¸

- **Day 1-2**: ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
  - [ ] MySQL ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
  - [ ] íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
  - [ ] PITR ìŠ¤í¬ë¦½íŠ¸
  - [ ] ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”

- **Day 3-4**: DR ì‚¬ì´íŠ¸
  - [ ] DR ì„œë²„ í”„ë¡œë¹„ì €ë‹
  - [ ] Docker Compose ì„¤ì •
  - [ ] ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
  - [ ] DNS ì „í™˜ ê³„íš

- **Day 5**: ë³µêµ¬ í…ŒìŠ¤íŠ¸
  - [ ] ì „ì²´ ë³µêµ¬ í…ŒìŠ¤íŠ¸
  - [ ] DR ì‚¬ì´íŠ¸ ì „í™˜ í…ŒìŠ¤íŠ¸
  - [ ] RTO/RPO ì¸¡ì •
  - [ ] ê°œì„ ì‚¬í•­ ë„ì¶œ

### Week 4: ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

**ëª©í‘œ**: ë°±ì—… ëª¨ë‹ˆí„°ë§ ë° ìë™í™” ê°œì„ 

- **Day 1-2**: ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
  - [ ] ë°±ì—… ìƒíƒœ API
  - [ ] Grafana ëŒ€ì‹œë³´ë“œ
  - [ ] Prometheus ë©”íŠ¸ë¦­
  - [ ] ì•Œë¦¼ ì„¤ì •

- **Day 3**: ê²€ì¦ ìë™í™”
  - [ ] ë°±ì—… ë¬´ê²°ì„± ê²€ì¦
  - [ ] ë°ì´í„° ì¼ê´€ì„± ì²´í¬
  - [ ] ìë™ ë³µêµ¬ í…ŒìŠ¤íŠ¸

- **Day 4**: ë¬¸ì„œí™”
  - [ ] ë°±ì—… ê°€ì´ë“œ ì™„ì„±
  - [ ] ë³µêµ¬ ë§¤ë‰´ì–¼
  - [ ] DRP ë¬¸ì„œ
  - [ ] ìš´ì˜ ê°€ì´ë“œ

- **Day 5**: ìµœì¢… ê²€í†  ë° ë°°í¬
  - [ ] ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
  - [ ] íŒ€ êµìœ¡
  - [ ] í”„ë¡œë•ì…˜ ë°°í¬
  - [ ] ëª¨ë‹ˆí„°ë§ í™•ì¸

---

## 11. ì°¸ê³  ìë£Œ

### 11.1 ë„êµ¬ ë° ì„œë¹„ìŠ¤

| ë„êµ¬                       | ìš©ë„             | ë§í¬              |
| -------------------------- | ---------------- | ----------------- |
| **mysqldump**              | MySQL ë°±ì—…       | docs.oracle.com   |
| **AWS S3**                 | ì›ê²© ë°±ì—…        | aws.amazon.com/s3 |
| **Elasticsearch Snapshot** | ê²€ìƒ‰ ë°ì´í„° ë°±ì—… | elastic.co        |
| **restic**                 | ì¦ë¶„ ë°±ì—… ë„êµ¬   | restic.net        |
| **BorgBackup**             | ì¤‘ë³µ ì œê±° ë°±ì—…   | borgbackup.org    |

### 11.2 ëª¨ë²” ì‚¬ë¡€

- **3-2-1 ê·œì¹™** ì¤€ìˆ˜
- **ì•”í˜¸í™”** ë°±ì—… ë°ì´í„°
- **ì •ê¸°ì ì¸ ë³µêµ¬ í…ŒìŠ¤íŠ¸**
- **ìë™í™”ëœ ê²€ì¦**
- **ë¬¸ì„œí™”**

---

**ì‘ì„±ì¼**: 2025-11-12  
**ì‘ì„±ì**: AUTOAGENTS  
**ë²„ì „**: 1.0
